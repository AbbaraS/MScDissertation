{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from monai.transforms import LoadImage, EnsureChannelFirst, Orientation, Compose, SaveImage, Transform\n",
    "from monai.bundle import ConfigParser, download\n",
    "from monai.data.meta_tensor import MetaTensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import SGD\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact\n",
    "from nibabel import Nifti1Image\n",
    "import nibabel as nib\n",
    "from totalsegmentator.python_api import totalsegmentator\n",
    "\n",
    "from monai.transforms import Resize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.mps.is_available())  # Should return True\n",
    "print(torch.backends.mps.is_built())  # Should return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "def show_scrollable_image(image, cmap=\"nipy_spectral\"):\n",
    "    \"\"\"\n",
    "    Displays a 3D array as a scrollable series of slices.\n",
    "    \n",
    "    Parameters:\n",
    "    - image (numpy.ndarray): A 3D numpy array (e.g., (H, W, D)) representing the image.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define a function to display each slice\n",
    "    def display_slice(slice_index):\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(image[:, :, slice_index], cmap=cmap)\n",
    "        plt.colorbar(label='HU')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Slice {slice_index + 1} / {image.shape[2]}\")\n",
    "        plt.show()\n",
    "    \n",
    "    # Create an interactive slider to scroll through slices\n",
    "    interact(display_slice, slice_index=(0, image.shape[2] - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nifti1image_to_metatensor(nifti_img: Nifti1Image) -> MetaTensor:\n",
    "    \"\"\"\n",
    "    Converts a Nifti1Image object to a MetaTensor with metadata.\n",
    "    Args:\n",
    "        nifti_img (Nifti1Image): A loaded NIfTI image.\n",
    "    Returns:\n",
    "        MetaTensor: A MONAI MetaTensor containing the image data and metadata.\n",
    "    \"\"\"\n",
    "    # Convert voxel data to PyTorch tensor\n",
    "    image_tensor = torch.tensor(nifti_img.get_fdata(), dtype=torch.float32)\n",
    "\n",
    "    # Extract metadata\n",
    "    metadata = {\n",
    "        \"affine\": torch.tensor(nifti_img.affine, dtype=torch.float32),  # Affine transformation matrix\n",
    "        \"spacing\": nifti_img.header.get_zooms(),  # Voxel spacing (x, y, z)\n",
    "        \"original_shape\": image_tensor.shape  # Store original shape for reference\n",
    "    }\n",
    "\n",
    "    # Create a MetaTensor with metadata\n",
    "    meta_tensor = MetaTensor(image_tensor, meta=metadata)\n",
    "\n",
    "    return meta_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00200037': {'vr': 'DS', 'Value': [1.0, 0.0, 0.0, 0.0, 1.0, 0.0]},\n",
       " '00200032': {'vr': 'DS', 'Value': [-156.223236, -166.379486, 21.399994]},\n",
       " '00280030': {'vr': 'DS', 'Value': [0.646484, 0.646484, 1.0]},\n",
       " 'spacing': array([0.646484, 0.646484, 1.      ]),\n",
       " 'lastImagePositionPatient': array([-156.223236, -166.379486, -246.600006]),\n",
       " spatial_shape: (512, 512, 269),\n",
       " space: RAS,\n",
       " original_affine: array([[ -0.646484,   0.      ,   0.      , 156.223236],\n",
       "        [  0.      ,  -0.646484,   0.      , 166.379486],\n",
       "        [  0.      ,   0.      ,  -1.      ,  21.399994],\n",
       "        [  0.      ,   0.      ,   0.      ,   1.      ]]),\n",
       " affine: tensor([[ -0.6465,   0.0000,   0.0000, 156.2232],\n",
       "         [  0.0000,  -0.6465,   0.0000, 166.3795],\n",
       "         [  0.0000,   0.0000,  -1.0000,  21.4000],\n",
       "         [  0.0000,   0.0000,   0.0000,   1.0000]], dtype=torch.float64),\n",
       " original_channel_dim: nan,\n",
       " 'filename_or_obj': '../data/Inputs/takotsubo_cases/AG 11370442/DICOM/1 A STD'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_file_path = \"../data/Inputs/normal_cases/AG 519880_37F\"\n",
    "input_file_path = \"../data/Inputs/takotsubo_cases/AG 11370442\"\n",
    "dicom_file_path = os.path.join(input_file_path, \"DICOM\")\n",
    "subfolders = sorted([f for f in os.listdir(dicom_file_path) if os.path.isdir(os.path.join(dicom_file_path, f))])\n",
    "\n",
    "if not subfolders:\n",
    "    raise FileNotFoundError(f\"No subfolders found in {dicom_file_path}\")\n",
    "\n",
    "dicom_file_path = os.path.join(dicom_file_path, subfolders[0])\n",
    "output_folder = input_file_path.replace(\"Inputs\", \"Outputs\")\n",
    "\n",
    "output_file = f\"{output_folder}/heart_resized.nii.gz\"\n",
    "\n",
    "image_loader = LoadImage(image_only=True)\n",
    "original_input_image = image_loader(dicom_file_path)\n",
    "\n",
    "original_input_image.meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "280f3169e8f64d5982b57550f9b285fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=134, description='slice_index', max=268), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_scrollable_image(original_input_image, cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you use this tool please cite: https://pubs.rsna.org/doi/10.1148/ryai.230024\n",
      "\n",
      "Generating rough segmentation for cropping...\n",
      "Converting dicom to nifti...\n",
      "  found image with shape (512, 512, 515)\n",
      "Resampling...\n",
      "  Resampled in 4.70s\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.08it/s]\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predicted in 6.98s\n",
      "Resampling...\n",
      "Converting dicom to nifti...\n",
      "  found image with shape (512, 512, 515)\n",
      "  cropping from (512, 512, 515) to (252, 211, 248)\n",
      "Predicting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "100%|██████████| 18/18 [00:35<00:00,  1.95s/it]\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Predicted in 52.07s\n",
      "Saving segmentations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/awabakram/git/Takotsubo-Syndrome/myenv3/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating heart_myocardium.nii.gz\n",
      "Creating heart_atrium_left.nii.gz\n",
      "Creating heart_ventricle_left.nii.gz\n",
      "Creating heart_ventricle_right.nii.gz\n",
      "Creating heart_atrium_right.nii.gz\n",
      "Creating aorta.nii.gz\n",
      "Creating pulmonary_artery.nii.gz\n",
      "  Saved in 14.96s\n"
     ]
    }
   ],
   "source": [
    "# option 1: provide input and output as file paths\n",
    "output_image = totalsegmentator(dicom_file_path, output_folder, license_number=\"aca_BWYHC6UQQFDU8A\", task=\"heartchambers_highres\", body_seg=True, device=\"mps\")\n",
    "# output_image = totalsegmentator(dicom_file_path, output_folder, license_number=\"aca_BWYHC6UQQFDU8A\", roi_subset=[\"heart\"], device=\"mps\")\n",
    "\n",
    "\n",
    "# option 2: provide input and output as nifti image objects\n",
    "# input_img = nib.load(dicom_file_path)\n",
    "# output_img = totalsegmentator(input_img)\n",
    "# print(output_img)\n",
    "# nib.save(output_img, data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208885fa715e4e9f9ddbf6458abedf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=257, description='slice_index', max=514), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "show_scrollable_image(nifti1image_to_metatensor(output_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'monai.data.meta_tensor.MetaTensor'>\n",
      "torch.Size([512, 512, 515])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e408d85b1f6f4ef0b6ec1747ff6d589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=257, description='slice_index', max=514), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the image\n",
    "left_ventricle_img = image_loader(f\"{output_folder}/heart_ventricle_left.nii.gz\")\n",
    "\n",
    "# Check the image type and shape\n",
    "print(type(left_ventricle_img))\n",
    "print(left_ventricle_img.shape)\n",
    "\n",
    "show_scrollable_image(left_ventricle_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_to_target_slices(image: MetaTensor, heart_mask: MetaTensor, target_width=512, target_height=512, target_slices=128):\n",
    "    \"\"\"\n",
    "    Extracts the heart region from the input scan and resizes it to a target number of slices, \n",
    "    preserving metadata while correctly computing voxel spacing.\n",
    "\n",
    "    Args:\n",
    "        image (MetaTensor): The input 3D CT/MRI scan.\n",
    "        heart_mask (MetaTensor): Binary mask indicating heart region.\n",
    "        target_slices (int, optional): Number of slices to resize to. Default is 128.\n",
    "\n",
    "    Returns:\n",
    "        MetaTensor: Resized image with updated metadata.\n",
    "    \"\"\"\n",
    "    if isinstance(heart_mask, MetaTensor):\n",
    "        heart_mask = heart_mask.as_tensor().cpu().numpy()\n",
    "    \n",
    "    z_indices = np.any(heart_mask > 0, axis=(0, 1))\n",
    "    heart_slices = np.where(z_indices)[0]\n",
    "    # print(heart_slices)\n",
    "    if len(heart_slices) == 0:\n",
    "        raise ValueError(\"No heart region found in the mask.\")\n",
    "    \n",
    "    start_slice = heart_slices[0]\n",
    "    end_slice = heart_slices[-1] + 1\n",
    "    \n",
    "    sliced_image = image[:, :, start_slice:end_slice]\n",
    "    if not isinstance(sliced_image, MetaTensor):\n",
    "        sliced_image = MetaTensor(sliced_image, meta=image.meta)\n",
    "    \n",
    "    height, width, original_depth = image.shape\n",
    "    # sliced_depth = sliced_image.shape[-1]\n",
    "\n",
    "    sliced_image = sliced_image.unsqueeze(0)  # Shape becomes (1, H, W, Z)\n",
    "    \n",
    "    resizer = Resize(spatial_size=(target_width,target_height,target_slices), mode=\"trilinear\", align_corners=True)\n",
    "    resized_image = resizer(sliced_image)\n",
    "    \n",
    "    resized_image = resized_image.squeeze(0)\n",
    "\n",
    "    # Update metadata\n",
    "    new_meta = image.meta.copy()  \n",
    "    \n",
    "    original_spacing = image.meta.get(\"spacing\", (1.0, 1.0, 1.0))\n",
    "    new_spacing = (\n",
    "        original_spacing[0],\n",
    "        original_spacing[1],\n",
    "        original_spacing[2] * (original_depth / target_slices)\n",
    "    )\n",
    "    new_meta[\"spacing\"] = new_spacing\n",
    "\n",
    "    # Keep affine transformation matrix but adjust slice resolution\n",
    "    if \"affine\" in new_meta:\n",
    "        new_meta[\"affine\"][-1, -1] *= (original_depth / target_slices)  # Adjust Z scaling\n",
    "\n",
    "    # Return resized MetaTensor with updated metadata\n",
    "    return MetaTensor(resized_image, meta=new_meta)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Shape: torch.Size([512, 512, 128])\n",
      "Updated Voxel Spacing: (0.738281, 0.738281, 2.5146484375)\n",
      "Updated Affine Matrix:\n",
      " tensor([[  -0.7383,    0.0000,    0.0000,  182.2000],\n",
      "        [  -0.0000,    0.7383,    0.0000, -193.0616],\n",
      "        [   0.0000,   -0.0000,    0.6250, -262.7000],\n",
      "        [   0.0000,    0.0000,    0.0000,    4.0234]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "full_image = nifti1image_to_metatensor(output_image)\n",
    "resized_image = resize_to_target_slices(full_image, full_image)\n",
    "\n",
    "print(\"Resized Shape:\", resized_image.shape)  # (H, W, 128)\n",
    "print(\"Updated Voxel Spacing:\", resized_image.meta[\"spacing\"])\n",
    "print(\"Updated Affine Matrix:\\n\", resized_image.meta[\"affine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512, 128])\n"
     ]
    }
   ],
   "source": [
    "print(resized_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f783ad84490540278ba10ed753b26aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=63, description='slice_index', max=127), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "show_scrollable_image(resized_image, cmap=\"grey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_name_formatter(metadict: dict, saver: Transform) -> dict:\n",
    "    \"\"\"Returns a kwargs dict for :py:meth:`FolderLayout.filename`,\n",
    "    according to the input metadata and SaveImage transform.\"\"\"\n",
    "    subject = \"heart_resized\"\n",
    "    patch_index = None\n",
    "    return {\"subject\": f\"{subject}\", \"idx\": patch_index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving\n",
      "2025-02-26 15:55:42,899 INFO image_writer.py:197 - writing: ../data/Outputs/normal_cases/AG 519880_37F/heart_resized.nii.gz\n",
      "saved\n"
     ]
    }
   ],
   "source": [
    "output_image_meta_tensor = nifti1image_to_metatensor(output_image)\n",
    "resized_image = resize_to_target_slices(output_image_meta_tensor, output_image_meta_tensor,target_height=256,target_width=256,target_slices=64)\n",
    "\n",
    "print(\"saving\")\n",
    "image_saver = SaveImage(output_dir=f\"{output_folder}\", separate_folder=False, output_postfix=\"\", output_name_formatter=custom_name_formatter)\n",
    "image_saver(resized_image)\n",
    "print(\"saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_segmentation_to_image(segmentation):\n",
    "    \"\"\"\n",
    "    Aligns the TotalSegmentator output (segmentation) with the original image\n",
    "    by flipping the z-axis of the segmentation mask.\n",
    "    \n",
    "    Parameters:\n",
    "        image (torch.Tensor or np.ndarray): Original image (H x W x D).\n",
    "        segmentation (torch.Tensor or np.ndarray): TotalSegmentator output (H x W x D).\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Segmentation aligned with the image.\n",
    "    \"\"\"\n",
    "   \n",
    "    # Flip along the z-axis (last dimension)\n",
    "    aligned_segmentation = torch.flip(segmentation, dims=[-1])\n",
    "    \n",
    "    return aligned_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_mask = align_segmentation_to_image(full_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a37d501e4a4c6cb0c62f17203a2c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=257, description='slice_index', max=514), Output()), _dom_classes=('widg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "show_scrollable_image(aligned_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_image_resized = resize_to_target_slices(original_input_image, aligned_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 256, 64])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92359ca56b8f4d00842efd5e59da1923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=31, description='slice_index', max=63), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_loader = LoadImage(image_only=True, ensure_channel_first=True)\n",
    "loaded_resized_image = image_loader(f\"{output_folder}/heart_resized.nii.gz\")\n",
    "loaded_resized_image = resized_image.squeeze(dim=-1)\n",
    "print(loaded_resized_image.shape)\n",
    "show_scrollable_image(loaded_resized_image)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
