{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecfe041",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install totalsegmentator\n",
    "!pip install dicom2nifti\n",
    "!pip install numpy==1.23.5 --force-reinstall\n",
    "!pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b44ad3e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sulei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.20) or chardet (5.2.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from totalsegmentator.python_api import totalsegmentator\n",
    "import dicom2nifti\n",
    "import dicom2nifti.convert_dicom\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68df21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d5b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from totalsegmentator.python_api import totalsegmentator\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.orientations import aff2axcodes\n",
    "#from nibabel import Nifti1Image\n",
    "\n",
    "#import dicom2nifti\n",
    "#import dicom2nifti.convert_dicom\n",
    "\n",
    "import SimpleITK as sitk\n",
    "#import scipy.ndimage\n",
    "#from skimage import measure\n",
    "#import imageio\n",
    "\n",
    "\n",
    "#from monai.data.meta_tensor import MetaTensor\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "import re\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a2ede6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_root = \"data/cases/\"\n",
    "\n",
    "for caseID in os.listdir(base_root):\n",
    "    if caseID.startswith('.'):\n",
    "        continue\n",
    "    folder_path = os.path.join(base_root, caseID)\n",
    "    #create_segments(folder_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84217af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename(folder):\n",
    "    # rename {folder}/ct_image.nii.gz to fullCT.nii.gz\n",
    "    # place all files other than fullCT.nii.gz in a subfolder called \"segments\"\n",
    "    old_path = os.path.join(folder, \"ct_image.nii.gz\")\n",
    "    new_path = os.path.join(folder, \"fullCT.nii.gz\")\n",
    "    if os.path.exists(old_path):\n",
    "        shutil.move(old_path, new_path)\n",
    "        print(f\"Renamed {old_path} to {new_path}\")\n",
    "    else:\n",
    "        print(f\"{old_path} does not exist.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bae6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing takotsubo_cases\n",
      "Moving AG_11370442 to data/cases/TTS_AG_11370442_68F\n",
      "Moving AMH_36922300 to data/cases/TTS_AMH_36922300_85F\n",
      "Moving AMS_22722383 to data/cases/TTS_AMS_22722383_75F\n",
      "Moving APH_3516218 to data/cases/TTS_APH_3516218_67F\n",
      "Moving BB_8903260 to data/cases/TTS_BB_8903260_78F\n",
      "Moving BEH_4037842 to data/cases/TTS_BEH_4037842_77F\n",
      "Moving BFM_10624765 to data/cases/TTS_BFM_10624765_79F\n",
      "Moving BLT_11022191 to data/cases/TTS_BLT_11022191_60F\n",
      "Moving CAMcD_10747764 to data/cases/TTS_CAMcD_10747764_80F\n",
      "Moving CDA_38093134 to data/cases/TTS_CDA_38093134_74F\n",
      "Moving CLB_50002879 to data/cases/TTS_CLB_50002879_65F\n",
      "Moving CML_11113354 to data/cases/TTS_CML_11113354_88F\n",
      "Moving CMS_4664231 to data/cases/TTS_CMS_4664231_91F\n",
      "Moving DCA_9939935 to data/cases/TTS_DCA_9939935_86F\n",
      "Moving DD_26362236 to data/cases/TTS_DD_26362236_63F\n",
      "Moving DEM_9902248 to data/cases/TTS_DEM_9902248_72F\n",
      "Moving DIW_10053411 to data/cases/TTS_DIW_10053411_89F\n",
      "Moving DJD_6122410 to data/cases/TTS_DJD_6122410_88F\n",
      "Moving DJK_2493 to data/cases/TTS_DJK_2493_53F\n",
      "Moving DJM_34687566 to data/cases/TTS_DJM_34687566_90M\n",
      "Moving ECW_33674557 to data/cases/TTS_ECW_33674557_89F\n",
      "Moving EIC_26844753 to data/cases/TTS_EIC_26844753_77F\n",
      "Moving ELD_30527501 to data/cases/TTS_ELD_30527501_83F\n",
      "Moving EMB_34404780 to data/cases/TTS_EMB_34404780_87F\n",
      "Moving FFJ_11086170 to data/cases/TTS_FFJ_11086170_86F\n",
      "Moving GA_39800503 to data/cases/TTS_GA_39800503_22F\n",
      "Moving GAB_25512591 to data/cases/TTS_GAB_25512591_90F\n",
      "Moving GB_10468072 to data/cases/TTS_GB_10468072_81F\n",
      "Moving GHM_4514352 to data/cases/TTS_GHM_4514352_81F\n",
      "Moving GJB_30653190 to data/cases/TTS_GJB_30653190_88M\n",
      "Moving GJI_25633926 to data/cases/TTS_GJI_25633926_66F\n",
      "Moving HSM_3468857 to data/cases/TTS_HSM_3468857_83F\n",
      "Moving IK_6526404 to data/cases/TTS_IK_6526404_85F\n",
      "Moving JAL_6996466 to data/cases/TTS_JAL_6996466_69F\n",
      "Moving JAQ_3124096 to data/cases/TTS_JAQ_3124096_93F\n",
      "Moving JD_48020 to data/cases/TTS_JD_48020_100F\n",
      "Moving JDMB_13788 to data/cases/TTS_JDMB_13788_72F\n",
      "Moving JDMB_137882 to data/cases/TTS_JDMB_137882_72F\n",
      "Moving JEB_6123921 to data/cases/TTS_JEB_6123921_76F\n",
      "Moving JET_40340663 to data/cases/TTS_JET_40340663_84F\n",
      "Moving JG_11495009 to data/cases/TTS_JG_11495009_90F\n",
      "Moving JL_4008074 to data/cases/TTS_JL_4008074_71F\n",
      "Moving JMB_38365177 to data/cases/TTS_JMB_38365177_73F\n",
      "Moving JMC_10182384 to data/cases/TTS_JMC_10182384_90F\n",
      "Moving JMCF_8687782 to data/cases/TTS_JMCF_8687782_62F\n",
      "Moving JML_11878832 to data/cases/TTS_JML_11878832_61F\n",
      "Moving JMMcC_4147591 to data/cases/TTS_JMMcC_4147591_77F\n",
      "Moving JNMP_2291631 to data/cases/TTS_JNMP_2291631_54F\n",
      "Moving JNMP_22916312 to data/cases/TTS_JNMP_22916312_54F\n",
      "Moving JOL_25671702 to data/cases/TTS_JOL_25671702_69F\n",
      "Moving JOS_38124012 to data/cases/TTS_JOS_38124012_68M\n",
      "Moving KA_28110559 to data/cases/TTS_KA_28110559_59F\n",
      "Moving KAL_7224116 to data/cases/TTS_KAL_7224116_57F\n",
      "Moving KEK_5853320 to data/cases/TTS_KEK_5853320_74F\n",
      "Moving LAM_5515176 to data/cases/TTS_LAM_5515176_65F\n",
      "Moving LB_23518517 to data/cases/TTS_LB_23518517_83F\n",
      "Moving LD_22194237 to data/cases/TTS_LD_22194237_63F\n",
      "Moving LET_4456356 to data/cases/TTS_LET_4456356_87F\n",
      "Moving LMA_3884426 to data/cases/TTS_LMA_3884426_78F\n",
      "Moving LMC_3629185 to data/cases/TTS_LMC_3629185_66F\n",
      "Moving LMD_22194237 to data/cases/TTS_LMD_22194237_63F\n",
      "Moving LW_12109724 to data/cases/TTS_LW_12109724_62F\n",
      "Moving MA_6894703 to data/cases/TTS_MA_6894703_78F\n",
      "Moving MB_12229480 to data/cases/TTS_MB_12229480_96F\n",
      "Moving MC_3887643 to data/cases/TTS_MC_3887643_88F\n",
      "Moving MDW_22867501 to data/cases/TTS_MDW_22867501_81F\n",
      "Moving MG_22519714 to data/cases/TTS_MG_22519714_73M\n",
      "Moving MGR_2545663 to data/cases/TTS_MGR_2545663_93M\n",
      "Moving MK_25733700 to data/cases/TTS_MK_25733700_98F\n",
      "Moving MMF_40610578 to data/cases/TTS_MMF_40610578_75F\n",
      "Moving MMStM_35433 to data/cases/TTS_MMStM_35433_70F\n",
      "Moving MVM_10108272 to data/cases/TTS_MVM_10108272_77F\n",
      "Moving NMC_90010075 to data/cases/TTS_NMC_90010075_73F\n",
      "Moving PAL_10614444 to data/cases/TTS_PAL_10614444_97F\n",
      "Moving PEB_5809140 to data/cases/TTS_PEB_5809140_94F\n",
      "Moving PEL_3437076 to data/cases/TTS_PEL_3437076_80F\n",
      "Moving PLM_36340719 to data/cases/TTS_PLM_36340719_61F\n",
      "Moving PMS_6674980 to data/cases/TTS_PMS_6674980_78F\n",
      "Moving RBB_5420187 to data/cases/TTS_RBB_5420187_86M\n",
      "Moving RMG_22721187 to data/cases/TTS_RMG_22721187_61M\n",
      "Moving SC_7249766 to data/cases/TTS_SC_7249766_82F\n",
      "Moving SES_28300911 to data/cases/TTS_SES_28300911_74F\n",
      "Moving SH_39969431 to data/cases/TTS_SH_39969431_78F\n",
      "Moving SKLL_5171467 to data/cases/TTS_SKLL_5171467_81F\n",
      "Moving SSA_35792472 to data/cases/TTS_SSA_35792472_73F\n",
      "Moving TS_2438216 to data/cases/TTS_TS_2438216_76F\n",
      "Moving WF_10497121 to data/cases/TTS_WF_10497121_62F\n",
      "Moving XZC_32444390 to data/cases/TTS_XZC_32444390_94F\n",
      "Moving YS_2685329 to data/cases/TTS_YS_2685329_53M\n",
      "Moving ZCC_3076288 to data/cases/TTS_ZCC_3076288_85F\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "def change_paths():\n",
    "    # folder paths\n",
    "    # TAKO = \"TTS\"\n",
    "    # NORMAL = \"Normal\"\n",
    "    # CNTRL\n",
    "    '''PatientID,Age,Gender\n",
    "        AD 12191953,51,1\n",
    "    '''\n",
    "    root = f\"data/cases/\" \n",
    "    old_path= f\"data/Inputs/takotsubo_cases/\"\n",
    "    print(f\"Processing takotsubo_cases\")\n",
    "    TTS_metadata = pd.read_csv(\"data/takotsubo_cases_metadata.csv\")\n",
    "    TTS_metadata['PatientID'] = TTS_metadata['PatientID'].str.strip()\n",
    "    TTS_metadata['Gender'] = TTS_metadata['Gender'].map({0: 'M', 1: 'F'})\n",
    "    for old_patient in os.listdir(old_path):\n",
    "        if old_patient.startswith('.'):\n",
    "            continue\n",
    "        \n",
    "        patient = old_patient.strip().replace(\" \", \"_\")\n",
    "        meta_row = TTS_metadata[TTS_metadata['PatientID'].str.replace(\" \", \"_\") == patient]\n",
    "        if meta_row.empty:\n",
    "            print(f\"No metadata found for {patient}, skipping...\")\n",
    "            continue\n",
    "        age = int(meta_row['Age'].values[0])\n",
    "        gender = meta_row['Gender'].values[0]\n",
    "        \n",
    "        \n",
    "        new_name= f\"TTS_{patient}_{age}{gender}\" #_ageG -> e.g. TTS_AD_12191953_51F\n",
    "        \n",
    "        new_path = os.path.join(root, new_name)\n",
    "        print(f\"Moving {patient} to {new_path}\")\n",
    "        shutil.move(os.path.join(old_path, old_patient), new_path)\n",
    "        #break\n",
    "change_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1212b680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing normal_cases\n",
      "Moving AB 10470318_90F to data/cases/CNTRL_AB_10470318_90F\n",
      "Moving AG 519880_37F to data/cases/CNTRL_AG_519880_37F\n",
      "Moving AIB 36444628_88F to data/cases/CNTRL_AIB_36444628_88F\n",
      "Moving AMB 08058471_74M to data/cases/CNTRL_AMB_08058471_74M\n",
      "Moving ASJ 05633540_68F to data/cases/CNTRL_ASJ_05633540_68F\n",
      "Moving ASSA 39309711_56F to data/cases/CNTRL_ASSA_39309711_56F\n",
      "Moving BA 37586690_62M to data/cases/CNTRL_BA_37586690_62M\n",
      "Moving BJB 42898_78F to data/cases/CNTRL_BJB_42898_78F\n",
      "Moving BMB 26209098_65M to data/cases/CNTRL_BMB_26209098_65M\n",
      "Moving BWB 08372559_71M to data/cases/CNTRL_BWB_08372559_71M\n",
      "Moving CAB 30473847_51F to data/cases/CNTRL_CAB_30473847_51F\n",
      "Moving CAD 35811017_49F to data/cases/CNTRL_CAD_35811017_49F\n",
      "Moving CAM 29734621_78F to data/cases/CNTRL_CAM_29734621_78F\n",
      "Moving CB 11607017_75F to data/cases/CNTRL_CB_11607017_75F\n",
      "Moving CEEB 08099780_60F to data/cases/CNTRL_CEEB_08099780_60F\n",
      "Moving CEK 02226835_80F to data/cases/CNTRL_CEK_02226835_80F\n",
      "Moving CMLB 50124639_67F to data/cases/CNTRL_CMLB_50124639_67F\n",
      "Moving DAB 37356987_82F to data/cases/CNTRL_DAB_37356987_82F\n",
      "Moving DB 24229841_67F to data/cases/CNTRL_DB_24229841_67F\n",
      "Moving DCE 22600738_50M to data/cases/CNTRL_DCE_22600738_50M\n",
      "Moving DEA 9230_52M to data/cases/CNTRL_DEA_9230_52M\n",
      "Moving DEMC 50496560_60M to data/cases/CNTRL_DEMC_50496560_60M\n",
      "Moving DJM 50424301_78M to data/cases/CNTRL_DJM_50424301_78M\n",
      "Moving DL 232051_72F to data/cases/CNTRL_DL_232051_72F\n",
      "Moving DMJ 07659402_76F to data/cases/CNTRL_DMJ_07659402_76F\n",
      "Moving DVMcC 39192026_54M to data/cases/CNTRL_DVMcC_39192026_54M\n",
      "Moving EB 07296072_74F to data/cases/CNTRL_EB_07296072_74F\n",
      "Moving EFD 12132080_80F to data/cases/CNTRL_EFD_12132080_80F\n",
      "Moving FB 192978_73M to data/cases/CNTRL_FB_192978_73M\n",
      "Moving GKW 27839323_65M to data/cases/CNTRL_GKW_27839323_65M\n",
      "Moving GML 05667308_58F to data/cases/CNTRL_GML_05667308_58F\n",
      "Moving HB 50159284_62F to data/cases/CNTRL_HB_50159284_62F\n",
      "Moving HMD 22248504_77F to data/cases/CNTRL_HMD_22248504_77F\n",
      "Moving HTNA 39573258_80F to data/cases/CNTRL_HTNA_39573258_80F\n",
      "Moving JAB 07917586_74M to data/cases/CNTRL_JAB_07917586_74M\n",
      "Moving JBM 11929965_71M to data/cases/CNTRL_JBM_11929965_71M\n",
      "Moving JSA 91708HDGH_67F to data/cases/CNTRL_JSA_91708HDGH_67F\n",
      "Moving KJS 32709594_63F to data/cases/CNTRL_KJS_32709594_63F\n",
      "Moving KLB 02269181_63F to data/cases/CNTRL_KLB_02269181_63F\n",
      "Moving KMC 92706_81F to data/cases/CNTRL_KMC_92706_81F\n",
      "Moving LAAB 06958326_90M to data/cases/CNTRL_LAAB_06958326_90M\n",
      "Moving LBH 22392393_71F to data/cases/CNTRL_LBH_22392393_71F\n",
      "Moving LFA 41168659_66F to data/cases/CNTRL_LFA_41168659_66F\n",
      "Moving LLM 24775207_66F to data/cases/CNTRL_LLM_24775207_66F\n",
      "Moving MA 00147663_60F to data/cases/CNTRL_MA_00147663_60F\n",
      "Moving MDB 50252695_27M to data/cases/CNTRL_MDB_50252695_27M\n",
      "Moving MJL 32231441_45F to data/cases/CNTRL_MJL_32231441_45F\n",
      "Moving MRB 05633250_74M to data/cases/CNTRL_MRB_05633250_74M\n",
      "Moving NEA 10026953_70M to data/cases/CNTRL_NEA_10026953_70M\n",
      "Moving NGC 50376742_65F to data/cases/CNTRL_NGC_50376742_65F\n",
      "Moving NLR 08251902_69F to data/cases/CNTRL_NLR_08251902_69F\n",
      "Moving NU00147883_60F to data/cases/CNTRL_NU00147883_60F\n",
      "Moving PDG 27972884_76F to data/cases/CNTRL_PDG_27972884_76F\n",
      "Moving PL 36050987_73M to data/cases/CNTRL_PL_36050987_73M\n",
      "Moving PLB 32190472_65F to data/cases/CNTRL_PLB_32190472_65F\n",
      "Moving RJCB 32157976_M40 to data/cases/CNTRL_RJCB_32157976_M40\n",
      "Moving RMB 09729021_67F to data/cases/CNTRL_RMB_09729021_67F\n",
      "Moving RNA 36366185_34F to data/cases/CNTRL_RNA_36366185_34F\n",
      "Moving RRJ 07177728_78M to data/cases/CNTRL_RRJ_07177728_78M\n",
      "Moving RSK 31115199_35M to data/cases/CNTRL_RSK_31115199_35M\n",
      "Moving SA 33363250_46F to data/cases/CNTRL_SA_33363250_46F\n",
      "Moving SBAE 22469423_79F to data/cases/CNTRL_SBAE_22469423_79F\n",
      "Moving SBMD 50080962_45F to data/cases/CNTRL_SBMD_50080962_45F\n",
      "Moving SD 37219755_36F to data/cases/CNTRL_SD_37219755_36F\n",
      "Moving SDA 50042444_68M to data/cases/CNTRL_SDA_50042444_68M\n",
      "Moving SLE 50347443_59F to data/cases/CNTRL_SLE_50347443_59F\n",
      "Moving SRS 09390469_32F to data/cases/CNTRL_SRS_09390469_32F\n",
      "Moving SS 10937555_61F to data/cases/CNTRL_SS_10937555_61F\n",
      "Moving TLW 07935802_99F to data/cases/CNTRL_TLW_07935802_99F\n",
      "Moving VI 22589683_86F to data/cases/CNTRL_VI_22589683_86F\n",
      "Moving VM 50032811_93F to data/cases/CNTRL_VM_50032811_93F\n",
      "Moving VMI 00101342_37F to data/cases/CNTRL_VMI_00101342_37F\n",
      "Moving WL 260776_64F to data/cases/CNTRL_WL_260776_64F\n",
      "Moving YPC 50401036_90M to data/cases/CNTRL_YPC_50401036_90M\n",
      "Moving ZCI 50491172_20F to data/cases/CNTRL_ZCI_50491172_20F\n"
     ]
    }
   ],
   "source": [
    "process_case()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260938af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL='normal_cases'\n",
    "TAKO='takotsubo_cases'\n",
    "\n",
    "case_path=f\"{NORMAL}/LAAB 06958326_90M\"  #OG shape (512, 111, 512)\n",
    "case_path=f\"{NORMAL}/SS 10937555_61F\"   #OG shape (512, 86, 512)\n",
    "\n",
    "base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/{case_path}\" \n",
    "base_input_root = f\"data/Inputs/{case_path}\"\n",
    "base_output_root = f\"data/Outputs/{case_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49480a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patientID in os.listdir(dicom_root):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_CT(volume_np, \n",
    "                spacing, \n",
    "                new_spacing=[1.0, 1.0, 1.0],\n",
    "                target_shape=(64, 64, 64), \n",
    "                original_affine=None):\n",
    "    \"\"\"\n",
    "    Resamples a CT volume using linear interpolation.\n",
    "    \"\"\"\n",
    "    sitk_img = sitk.GetImageFromArray(np.transpose(volume_np, (2, 1, 0)))\n",
    "    sitk_img.SetSpacing([float(s) for s in spacing[::-1]])\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    \n",
    "    original_size = np.array(sitk_img.GetSize(), dtype=np.int32)\n",
    "    original_spacing = np.array(sitk_img.GetSpacing())\n",
    "    new_size = np.round(original_size * (original_spacing / new_spacing)).astype(int).tolist()\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetOutputDirection(sitk_img.GetDirection())\n",
    "    resampler.SetOutputOrigin(sitk_img.GetOrigin())\n",
    "    resampled = resampler.Execute(sitk_img)\n",
    "\n",
    "    direction = np.array(resampled.GetDirection()).reshape(3, 3)\n",
    "    spacing_arr = np.array(resampled.GetSpacing())\n",
    "\n",
    "    origin = original_affine[:3, 3] if original_affine is not None else np.array(resampled.GetOrigin())\n",
    "    affine = np.eye(4)\n",
    "    affine[:3, :3] = direction * spacing_arr[:, None]\n",
    "    affine[:3, 3] = origin\n",
    "\n",
    "    resampled_np = np.transpose(sitk.GetArrayFromImage(resampled), (2, 1, 0))\n",
    "    zoom_factors = [t / s for t, s in zip(target_shape, resampled_np.shape)]\n",
    "    volume_final = scipy.ndimage.zoom(resampled_np, zoom=zoom_factors, order=1)\n",
    "\n",
    "    return volume_final, affine, resampled\n",
    "\n",
    "\n",
    "def resample_mask(volume_np, reference_image,\n",
    "                  target_shape=(64, 64, 64), original_affine=None):\n",
    "    \"\"\"\n",
    "    Resamples a binary or label mask using nearest-neighbour interpolation,\n",
    "    aligned to the given reference image (typically a CT volume).\n",
    "    \"\"\"\n",
    "    # Convert to SimpleITK image (z, y, x) format\n",
    "    sitk_img = sitk.GetImageFromArray(np.transpose(volume_np, (2, 1, 0)))\n",
    "\n",
    "    # Match mask to reference image geometry\n",
    "    sitk_img.SetSpacing(reference_image.GetSpacing())  # optional but safe\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resampler.SetReferenceImage(reference_image)\n",
    "\n",
    "    resampled = resampler.Execute(sitk_img)\n",
    "\n",
    "    # Recover affine from reference image and spacing\n",
    "    direction = np.array(resampled.GetDirection()).reshape(3, 3)\n",
    "    spacing_arr = np.array(resampled.GetSpacing())\n",
    "    origin = original_affine[:3, 3] if original_affine is not None else np.array(resampled.GetOrigin())\n",
    "\n",
    "    affine = np.eye(4)\n",
    "    affine[:3, :3] = direction * spacing_arr[:, None]\n",
    "    affine[:3, 3] = origin\n",
    "\n",
    "    # Convert to NumPy in (x, y, z) order\n",
    "    resampled_np = np.transpose(sitk.GetArrayFromImage(resampled), (2, 1, 0))\n",
    "\n",
    "    # Resize to uniform shape\n",
    "    zoom_factors = [t / s for t, s in zip(target_shape, resampled_np.shape)]\n",
    "    volume_final = scipy.ndimage.zoom(resampled_np, zoom=zoom_factors, order=0)\n",
    "\n",
    "    return volume_final, affine, resampled\n",
    "\n",
    "\n",
    "def crop_trim_resample(case, Segment_root):\n",
    "    # === Step 3 - Crop, trim, and resample heart ===\n",
    "\n",
    "    OG_file = load_nifti(get_segments_paths(Segment_root))\n",
    "    lv = OG_file[\"LV\"][\"data\"]\n",
    "    rv = OG_file[\"RV\"][\"data\"]\n",
    "    la = OG_file[\"LA\"][\"data\"]\n",
    "    ra = OG_file[\"RA\"][\"data\"]\n",
    "    myo = OG_file[\"MYO\"][\"data\"]\n",
    "    og_ct_data = OG_file[\"CT\"][\"data\"]\n",
    "    og_ct_voxel = OG_file[\"CT\"][\"voxel\"]\n",
    "    og_affine=OG_file[\"CT\"][\"affine\"]\n",
    "    # Combine masks to find heart bounding box\n",
    "    binary_mask = ((lv + rv + la + ra + myo) > 0).astype(np.uint8)   # (sum of positive labels across all masks)  & turn the summed array into a binary mask\n",
    "    x_min, y_min, z_min = np.array(np.where(binary_mask)).min(axis=1)\n",
    "    x_max, y_max, z_max = np.array(np.where(binary_mask)).max(axis=1)\n",
    "    \n",
    "    # calculate crop boundaries (3D bounding box) \n",
    "    # identify min and max voxel coordinates where heart structures are present\n",
    "    x0, x1 = max(x_min, 0), min(x_max, og_ct_data.shape[0])\n",
    "    y0, y1 = max(y_min, 0), min(y_max, og_ct_data.shape[1])\n",
    "    z0, z1 = max(z_min, 0), min(z_max, og_ct_data.shape[2])\n",
    "    \n",
    "    # crop volumes with bounding box coordinates\n",
    "    ct_crop = og_ct_data[x0:x1, y0:y1, z0:z1]\n",
    "    lv_crop = lv[x0:x1, y0:y1, z0:z1]\n",
    "    rv_crop = rv[x0:x1, y0:y1, z0:z1]\n",
    "    la_crop = la[x0:x1, y0:y1, z0:z1]\n",
    "    ra_crop = ra[x0:x1, y0:y1, z0:z1]\n",
    "    myo_crop = myo[x0:x1, y0:y1, z0:z1]\n",
    "    \n",
    "    case.cropped_shape = ct_crop.shape\n",
    "    \n",
    "    # Further trim empty slices\n",
    "    # binary_mask = (sum of positive labels across all masks)  & turn the summed array back into a binary mask\n",
    "    binary_mask = ((lv_crop + rv_crop + la_crop + ra_crop + myo_crop) > 0).astype(np.uint8)\n",
    "    x_empty_indices = [i for i in range(binary_mask.shape[0]) if not np.any(binary_mask[i, :, :])]\n",
    "    y_empty_indices = [i for i in range(binary_mask.shape[1]) if not np.any(binary_mask[:, i, :])]\n",
    "    z_empty_indices = [i for i in range(binary_mask.shape[2]) if not np.any(binary_mask[:, :, i])]\n",
    "    \n",
    "    \n",
    "    #print(f\"cropped CT shape: {ct_crop.shape}, og_ct_voxel: {og_ct_voxel}\")\n",
    "    if x_empty_indices or y_empty_indices or z_empty_indices:\n",
    "        case.log_error(\n",
    "        f\"Empty slices — \"\n",
    "        f\"X: {x_empty_indices if x_empty_indices else 'None'}, \"\n",
    "        f\"Y: {y_empty_indices if y_empty_indices else 'None'}, \"\n",
    "        f\"Z: {z_empty_indices if z_empty_indices else 'None'} \"\n",
    "            )\n",
    "    \n",
    "    \n",
    "    ct_res, ct_affine, ct_resampled = resample_CT(ct_crop, \n",
    "                                             og_ct_voxel, \n",
    "                                             original_affine=og_affine)\n",
    "    lv_res, lv_affine, lv_resampled = resample_mask(lv_crop, ct_resampled, original_affine=og_affine)\n",
    "    \n",
    "    \n",
    "def crop(case):\n",
    "    # === Step 3 - Crop, trim, and resample heart ===\n",
    "    lv = case.lv\n",
    "    rv = case.rv\n",
    "    la = case.la\n",
    "    ra = case.ra\n",
    "    myo = case.myo\n",
    "    fullCT_data = case.ct_data\n",
    "    fullCT_voxel = case.ct_voxel\n",
    "    \n",
    "    binary_mask = ((lv + rv + la + ra + myo) > 0).astype(np.uint8)   # (sum of positive labels across all masks)  & turn the summed array into a binary mask\n",
    "    x_min, y_min, z_min = np.array(np.where(binary_mask)).min(axis=1)\n",
    "    x_max, y_max, z_max = np.array(np.where(binary_mask)).max(axis=1)\n",
    "    \n",
    "    # calculate crop boundaries (3D bounding box) \n",
    "    # identify min and max voxel coordinates where heart structures are present\n",
    "    x0, x1 = max(x_min, 0), min(x_max, og_ct_data.shape[0])\n",
    "    y0, y1 = max(y_min, 0), min(y_max, og_ct_data.shape[1])\n",
    "    z0, z1 = max(z_min, 0), min(z_max, og_ct_data.shape[2])\n",
    "    \n",
    "    case.log_error( f\"3D bounding box coordinates- \"\n",
    "                    f\"x: {x0}-{x1}, \"\n",
    "                    f\"y: {y0}-{y1}, \"\n",
    "                    f\"z: {z0}-{z1} \")\n",
    "    \n",
    "    # crop volumes with bounding box coordinates\n",
    "    ct_crop = og_ct_data[x0:x1, y0:y1, z0:z1]\n",
    "    lv_crop = lv[x0:x1, y0:y1, z0:z1]\n",
    "    rv_crop = rv[x0:x1, y0:y1, z0:z1]\n",
    "    la_crop = la[x0:x1, y0:y1, z0:z1]\n",
    "    ra_crop = ra[x0:x1, y0:y1, z0:z1]\n",
    "    myo_crop = myo[x0:x1, y0:y1, z0:z1]\n",
    "    \n",
    "    case.cropped_shape = ct_crop.shape\n",
    "    \n",
    "    # Further trim empty slices\n",
    "    # binary_mask = (sum of positive labels across all masks)  & turn the summed array back into a binary mask\n",
    "    binary_mask = ((lv_crop + rv_crop + la_crop + ra_crop + myo_crop) > 0).astype(np.uint8)\n",
    "    x_empty_indices = [i for i in range(binary_mask.shape[0]) if not np.any(binary_mask[i, :, :])]\n",
    "    y_empty_indices = [i for i in range(binary_mask.shape[1]) if not np.any(binary_mask[:, i, :])]\n",
    "    z_empty_indices = [i for i in range(binary_mask.shape[2]) if not np.any(binary_mask[:, :, i])]\n",
    "    \n",
    "    \n",
    "    #print(f\"cropped CT shape: {ct_crop.shape}, og_ct_voxel: {og_ct_voxel}\")\n",
    "    if x_empty_indices or y_empty_indices or z_empty_indices:\n",
    "        case.log_error(\n",
    "        f\"Empty slices — \"\n",
    "        f\"X: {x_empty_indices if x_empty_indices else 'None'}, \"\n",
    "        f\"Y: {y_empty_indices if y_empty_indices else 'None'}, \"\n",
    "        f\"Z: {z_empty_indices if z_empty_indices else 'None'} \"\n",
    "            )\n",
    "    \n",
    "\n",
    "def append_case_to_csv(case_obj, csv_path):\n",
    "    df = pd.DataFrame([case_obj.to_dict()])  \n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', index=False, header=write_header)        \n",
    "\n",
    "CNTRL='CNTRL'\n",
    "TTS='TTS'\n",
    "        \n",
    "def process_case(group):\n",
    "    \n",
    "    if group == NORMAL:\n",
    "        CNTRL_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/normal_cases\" \n",
    "    elif group == TAKO:\n",
    "        base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/takotsubo_cases\"\n",
    "    base_root = f\"data/cases/\"\n",
    "    csv_path = f\"data/case_summary.csv\"\n",
    "    \n",
    "    # Step 1: Load already processed patient IDs from CSV\n",
    "    #if os.path.exists(csv_path):\n",
    "    #    existing_df = pd.read_csv(csv_path)\n",
    "    #    already_processed = set(existing_df[\"Case\"].astype(str))  # Assuming \"Case\" column stores patient_id\n",
    "    #else:\n",
    "    #    already_processed = set()\n",
    "\n",
    "    for patientID in os.listdir(base_dicom_root):\n",
    "        case_id=f\"{group}_{patientID}\"\n",
    "        case = SampleInfo(patient_id=case_id, \n",
    "                          path=SamplePath(\n",
    "              dicom_dir=os.path.join(base_dicom_root, patientID, \"DICOM\")\n",
    "            , patient_dir=os.path.join(base_root, case_id)\n",
    "            , segments_dir=os.path.join(base_root, case_id, \"Segments\")\n",
    "            , cropped_dir=os.path.join(base_root, case_id, \"Cropped\")\n",
    "            , resampled_dir=os.path.join(base_root, case_id, \"Resampled\")\n",
    "            , ctSlices_dir=os.path.join(base_root, case_id, \"CT_Slices\")\n",
    "            , segmentSlices_dir=os.path.join(base_root, case_id, \"Segment_Slices\")\n",
    "            , pngSlices_dir=os.path.join(base_root, case_id, \"PNG_Slices\"))) \n",
    "        \n",
    "        os.makedirs(case.path.patient_dir, exist_ok=True)\n",
    "        os.makedirs(case.path.segments_dir, exist_ok=True)\n",
    "        os.makedirs(case.path.cropped_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.resampled_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.ctSlices_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.segmentSlices_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.pngSlices_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        \n",
    "        #if case_id in already_processed:\n",
    "        #    print(f\"Skipping already processed: {case_id}\")\n",
    "        #    continue\n",
    "        #print(f\"Patient ID: {patientID}\")\n",
    "   \n",
    "        \n",
    "        \n",
    "        # Load fullCT\n",
    "        if not os.path.exists(case.path.fullCT):\n",
    "            dicom2nifti.convert_dicom.dicom_series_to_nifti(case.path.dicom_dir, case.path.fullCT,)\n",
    "            case.fullCTnib = nib.load(case.path.fullCT)\n",
    "                \n",
    "            _ = totalsegmentator(\n",
    "                input_path=case.path.fullCT, \n",
    "                output_path=case.path.segments_dir,\n",
    "                license_number=\"aca_BWYHC6UQQFDU8A\",\n",
    "                task=\"heartchambers_highres\", \n",
    "                body_seg=True,\n",
    "                preview=True,\n",
    "                radiomics=True\n",
    "            )\n",
    "        \n",
    "        \n",
    "        crop(case)\n",
    "        \n",
    "        # Check for resampled image\n",
    "        if not os.path.exists(case.path.croppedCT):\n",
    "            case.log_error(\"cropped_ct.nii.gz not found\")\n",
    "            missing = [key for key, path in case.path.segments.items() if not os.path.exists(path)]\n",
    "            case.missing_segments = missing\n",
    "            append_case_to_csv(case, csv_path)\n",
    "            continue\n",
    "\n",
    "        # Process resampled image\n",
    "        case.resampled = True\n",
    "        resampled_img = nib.load(resampled_path)\n",
    "        case.new_shape = resampled_img.shape\n",
    "        case.new_voxel = tuple(round(s, 3) for s in resampled_img.header.get_zooms())\n",
    "        case.new_orientation = aff2axcodes(resampled_img.affine)\n",
    "        \n",
    "        # Collect slice names\n",
    "        for slice in os.listdir(nii_slice_dir):\n",
    "            # if slice starts with ctX_ add file name to case.X_slices\n",
    "            if slice.startswith(\"ctX_\"):\n",
    "                case.X_slices.append(slice)\n",
    "            # if slice starts with ctY_ add file name to case.Y_slices\n",
    "            elif slice.startswith(\"ctY_\"):\n",
    "                case.Y_slices.append(slice)\n",
    "            # if slice starts with ctZ_ add file name to case.Z_slices\n",
    "            elif slice.startswith(\"ctZ_\"):\n",
    "                case.Z_slices.append(slice)\n",
    "            \n",
    "        crop(case, segment_path)\n",
    "        append_case_to_csv(case, csv_path)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce5ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: AD 12191953\n",
      "Patient ID: AG 11370442\n",
      "Patient ID: AMH 36922300\n",
      "Patient ID: AMS 22722383\n",
      "Patient ID: APH 3516218\n",
      "Patient ID: BB 8903260\n",
      "Patient ID: BEH 4037842\n",
      "Patient ID: BFM 10624765\n",
      "Patient ID: BLT 11022191\n",
      "Patient ID: CAMcD 10747764\n",
      "Patient ID: CDA 38093134\n",
      "Patient ID: CLB 50002879\n",
      "Patient ID: CML 11113354\n",
      "Patient ID: CMS 4664231\n",
      "Patient ID: DCA 9939935\n",
      "Patient ID: DD 26362236\n",
      "Patient ID: DEM 9902248\n",
      "Patient ID: DIW 10053411\n",
      "Patient ID: DJD 6122410\n",
      "Patient ID: DJK 2493\n",
      "Patient ID: DJM 34687566\n",
      "Patient ID: ECW 33674557\n",
      "Patient ID: EIC 26844753\n",
      "Patient ID: ELD 30527501\n",
      "Patient ID: EMB 34404780\n",
      "Patient ID: FFJ 11086170\n",
      "Patient ID: GA 39800503\n",
      "Patient ID: GAB 25512591\n",
      "Patient ID: GB 10468072\n",
      "Patient ID: GHM 4514352\n",
      "Patient ID: GJB 30653190\n",
      "Patient ID: GJI 25633926\n",
      "Patient ID: HSM 3468857\n",
      "Patient ID: IK 6526404\n",
      "Patient ID: JAL 6996466\n",
      "Patient ID: JAQ 3124096\n",
      "Patient ID: JD 48020\n",
      "Patient ID: JDMB 13788\n",
      "Patient ID: JDMB 137882\n",
      "Patient ID: JEB 6123921\n",
      "Patient ID: JET 40340663\n",
      "Patient ID: JG 11495009\n",
      "Patient ID: JL 4008074\n",
      "Patient ID: JMB 38365177\n",
      "Patient ID: JMC 10182384\n",
      "Patient ID: JMCF 8687782\n",
      "Patient ID: JML 11878832\n",
      "Patient ID: JMMcC 4147591\n",
      "Patient ID: JNMP 2291631\n",
      "Patient ID: JNMP 22916312\n",
      "Patient ID: JOL 25671702\n",
      "Patient ID: JOS 38124012\n",
      "Patient ID: KA 28110559\n",
      "Patient ID: KAL 7224116\n",
      "Patient ID: KEK 5853320\n",
      "Patient ID: LAM 5515176\n",
      "Patient ID: LB 23518517\n",
      "Patient ID: LD 22194237\n",
      "Patient ID: LET 4456356\n",
      "Patient ID: LMA 3884426\n",
      "Patient ID: LMC 3629185\n",
      "Patient ID: LMD 22194237\n",
      "Patient ID: LW 12109724\n",
      "Patient ID: MA 6894703\n",
      "Patient ID: MB 12229480\n",
      "Patient ID: MC 3887643\n",
      "Patient ID: MDW 22867501\n",
      "Patient ID: MG 22519714\n",
      "Patient ID: MGR 2545663\n",
      "Patient ID: MK 25733700\n",
      "Patient ID: MMF 40610578\n",
      "Patient ID: MMStM 35433\n",
      "Patient ID: MVM 10108272\n",
      "Patient ID: NMC 90010075\n",
      "Patient ID: PAL 10614444\n",
      "Patient ID: PEB 5809140\n",
      "Patient ID: PEL 3437076\n",
      "Patient ID: PLM 36340719\n",
      "Patient ID: PMS 6674980\n",
      "Patient ID: RBB 5420187\n",
      "Patient ID: RMG 22721187\n",
      "Patient ID: SC 7249766\n",
      "Patient ID: SES 28300911\n",
      "Patient ID: SH 39969431\n",
      "Patient ID: SKLL 5171467\n",
      "Patient ID: SSA 35792472\n",
      "Patient ID: TS 2438216\n",
      "Patient ID: WF 10497121\n",
      "Patient ID: XZC 32444390\n",
      "Patient ID: YS 2685329\n",
      "Patient ID: ZCC 3076288\n"
     ]
    }
   ],
   "source": [
    "process_case(TAKO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path=f\"{NORMAL}/SS 10937555_61F\"   #OG shape (512, 86, 512)\n",
    "\n",
    "Segment_root = f\"data/Inputs/{case_path}\"\n",
    "new_output_root = f\"data/New_Outputs/{case_path}\"\n",
    "os.makedirs(new_output_root, exist_ok=True)\n",
    "crop_trim_resample_heart(Segment_root, new_output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "case=TAKO\n",
    "\n",
    "patientID = f\"{TAKO}/AG 11370442\"\n",
    "patientID = f\"{TAKO}/JMB 38365177\"\n",
    "patientID = f\"{TAKO}/JNMP 22916312\"\n",
    "patientID = f\"{TAKO}/HSM 3468857\"\n",
    "patientID = f\"{TAKO}/AMS 22722383\"\n",
    "patientID = f\"{TAKO}/BFM 10624765\"\n",
    "patientID = f\"{TAKO}/BLT 11022191\"\n",
    "patientID = f\"{TAKO}/EIC 26844753\"\n",
    "patientID = f\"{TAKO}/JDMB 137882\"\n",
    "\n",
    "OG_file_paths[\"LV\"]\n",
    "OG_file_paths[\"RV\"]\n",
    "OG_file_paths[\"LA\"]\n",
    "OG_file_paths[\"RA\"]\n",
    "OG_file_paths[\"MYO\"]\n",
    "OG_file_paths[\"CT\"]\n",
    "\n",
    "cropped_file_paths[\"Mask\"]\n",
    "cropped_file_paths[\"CT\"]\n",
    "cropped_file_paths[\"LV\"]\n",
    "cropped_file_paths[\"RV\"]\n",
    "cropped_file_paths[\"LA\"]\n",
    "cropped_file_paths[\"RA\"]\n",
    "cropped_file_paths[\"MYO\"]\n",
    "\n",
    "'''\n",
    "import os\n",
    "case=TAKO\n",
    "patientID = \"AG 11370442\"\n",
    "\n",
    "base_input_root = f\"data/Inputs/{case}\" #/{patient}\n",
    "base_output_root = f\"data/Outputs/{case}\" #/{patient}\n",
    "input_folder = os.path.join(base_input_root, patientID)\n",
    "output_folder = os.path.join(base_output_root, patientID)\n",
    "png_slices_folder=os.path.join(output_folder, \"png_slices\")\n",
    "\n",
    "cropped_file_paths = get_cropped_file_paths(output_folder)\n",
    "OG_file_paths = get_OG_file_paths(input_folder)\n",
    "\n",
    "#slice_CT(output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_trim_resample_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "\n",
    "class SingleBranchCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(SingleBranchCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1)  # (B, 16, H, W)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2)                                        # (B, 16, H/2, W/2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)            # (B, 32, H/2, W/2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2)                                        # (B, 32, H/4, W/4)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(0.3)  # Dropout for feature maps\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        return x  # Output shape: (B, 32, H/4, W/4)\n",
    "\n",
    "class MultiViewCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, input_size=(65, 65), use_metadata=False):\n",
    "        super(MultiViewCNN, self).__init__()\n",
    "\n",
    "        self.use_metadata = use_metadata\n",
    "        H, W = input_size\n",
    "\n",
    "        # Three branches\n",
    "        self.axial_branch = SingleBranchCNN(in_channels)\n",
    "        self.sagittal_branch = SingleBranchCNN(in_channels)\n",
    "        self.coronal_branch = SingleBranchCNN(in_channels)\n",
    "\n",
    "        # Output feature map size after 2x MaxPool2d(2)\n",
    "        flattened_size = 32 * (H // 4) * (W // 4)  # each branch output flattened\n",
    "\n",
    "        total_features = 3 * flattened_size       # all branches\n",
    "        if use_metadata:\n",
    "            total_features += 2  # e.g. age and gender\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(total_features, 128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification (output: logit)\n",
    "\n",
    "    def forward(self, axial, sagittal, coronal, meta=None):\n",
    "        a = self.axial_branch(axial)\n",
    "        s = self.sagittal_branch(sagittal)\n",
    "        c = self.coronal_branch(coronal)\n",
    "\n",
    "        a = a.view(a.size(0), -1)  # flatten\n",
    "        s = s.view(s.size(0), -1)\n",
    "        c = c.view(c.size(0), -1)\n",
    "\n",
    "        x = torch.cat([a, s, c], dim=1)\n",
    "\n",
    "        if self.use_metadata and meta is not None:\n",
    "            x = torch.cat([x, meta], dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)  # no sigmoid here (use BCEWithLogitsLoss)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc624c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing normal_cases\n",
      "Processing takotsubo_cases\n",
      "Takotsubo: 81, Normal: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sulei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Train Loss: 0.9971 | Val Loss: 0.6446 | Train Acc: 52.29% | LR: 0.000100\n",
      "Epoch [2/50] | Train Loss: 0.6598 | Val Loss: 0.5989 | Train Acc: 65.14% | LR: 0.000100\n",
      "Epoch [3/50] | Train Loss: 0.5735 | Val Loss: 0.5771 | Train Acc: 67.89% | LR: 0.000100\n",
      "Epoch [4/50] | Train Loss: 0.5403 | Val Loss: 0.5984 | Train Acc: 72.48% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [5/50] | Train Loss: 0.4076 | Val Loss: 0.5515 | Train Acc: 82.57% | LR: 0.000100\n",
      "Epoch [6/50] | Train Loss: 0.4270 | Val Loss: 0.5997 | Train Acc: 82.57% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [7/50] | Train Loss: 0.3281 | Val Loss: 0.4957 | Train Acc: 87.16% | LR: 0.000100\n",
      "Epoch [8/50] | Train Loss: 0.3458 | Val Loss: 0.5179 | Train Acc: 88.07% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [9/50] | Train Loss: 0.2221 | Val Loss: 0.6800 | Train Acc: 89.91% | LR: 0.000100\n",
      "No improvement in val loss (2/3)\n",
      "Epoch [10/50] | Train Loss: 0.1738 | Val Loss: 0.5386 | Train Acc: 95.41% | LR: 0.000100\n",
      "No improvement in val loss (3/3)\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "metadata, labels, slices = load_dataset()\n",
    "dataset = SliceDataset(\n",
    "    slices_dict=slices,          \n",
    "    metadata_dict=metadata,      \n",
    "    labels_dict=labels           \n",
    ")\n",
    "\n",
    "takotsubo_count = sum(1 for sample in dataset if sample[\"label\"].item() == 1)\n",
    "normal_count = sum(1 for sample in dataset if sample[\"label\"].item() == 0)\n",
    "\n",
    "print(f\"Takotsubo: {takotsubo_count}, Normal: {normal_count}\")\n",
    "\n",
    "dataset_loader = DataLoaderModule(dataset, batch_size=1)\n",
    "\n",
    "# Model setup\n",
    "model = MultiViewCNN(in_channels=3, input_size=(65, 65), use_metadata=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#class_weight = takotsubo_count / normal_count if normal_count > 0 else 1.0\n",
    "pos_weight = torch.tensor([takotsubo_count / normal_count])  \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "train_loader = dataset_loader.get_train_loader()\n",
    "val_loader = dataset_loader.get_val_loader()\n",
    "test_loader = dataset_loader.get_test_loader()\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "threshold_cutoff = 0.5  # threshold for binary classification\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "num_epochs = 50  # longer max epochs now\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x_axial = batch[\"axial\"].to(device)\n",
    "        x_sagittal = batch[\"sagittal\"].to(device)\n",
    "        x_coronal = batch[\"coronal\"].to(device)\n",
    "        x_meta = batch[\"meta\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > threshold_cutoff).float()\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ====== Validation ======\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_axial = batch[\"axial\"].to(device)\n",
    "            x_sagittal = batch[\"sagittal\"].to(device)\n",
    "            x_coronal = batch[\"coronal\"].to(device)\n",
    "            x_meta = batch[\"meta\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Train Acc: {train_acc:.2f}% | LR: {current_lr:.6f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "    # ====== Early stopping check ======\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")  # save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in val loss ({patience_counter}/{patience})\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# ========== TEST EVALUATION WITH ROC AUC ========== #\n",
    "\n",
    "\n",
    "# Load best model\n",
    "torch.save(model.state_dict(), \"best_model.pt\")\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_prob = []\n",
    "threshold_cutoff = 0.5  # threshold for binary classification\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_axial = batch[\"axial\"].to(device)\n",
    "        x_sagittal = batch[\"sagittal\"].to(device)\n",
    "        x_coronal = batch[\"coronal\"].to(device)\n",
    "        x_meta = batch[\"meta\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()  # shape (B, 1)\n",
    "\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_prob.extend(probs)\n",
    "\n",
    "# Flatten\n",
    "y_true = [int(x) for x in y_true]\n",
    "y_prob = [float(p) for p in y_prob]\n",
    "y_pred = [int(p > threshold_cutoff) for p in y_prob]\n",
    "\n",
    "# Report\n",
    "print(\"\\n📊 Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Takotsubo\"]))\n",
    "\n",
    "# ROC AUC\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "print(f\"🎯 ROC AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# ROC Curve plot (optional)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Takotsubo\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, meta):\n",
    "        # Create dummy tensors for image branches\n",
    "        batch_size = meta.size(0)\n",
    "        dummy = torch.zeros((batch_size, 3, 65, 65)).to(meta.device)\n",
    "        return self.model(dummy, dummy, dummy, meta)\n",
    "    \n",
    "class MultiModalWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, axial, sagittal, coronal, meta):\n",
    "        return self.model(axial, sagittal, coronal, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect background (for DeepExplainer) and test examples\n",
    "bg_axial, bg_sagittal, bg_coronal, bg_meta = [], [], [], []\n",
    "test_axial, test_sagittal, test_coronal, test_meta = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataset_loader.get_val_loader()):\n",
    "        if i >= 10: break  # Limit background\n",
    "        bg_axial.append(batch[\"axial\"])\n",
    "        bg_sagittal.append(batch[\"sagittal\"])\n",
    "        bg_coronal.append(batch[\"coronal\"])\n",
    "        bg_meta.append(batch[\"meta\"])\n",
    "\n",
    "    for batch in dataset_loader.get_test_loader():\n",
    "        test_axial.append(batch[\"axial\"])\n",
    "        test_sagittal.append(batch[\"sagittal\"])\n",
    "        test_coronal.append(batch[\"coronal\"])\n",
    "        test_meta.append(batch[\"meta\"])\n",
    "\n",
    "# Stack all background and test tensors\n",
    "bg_input = [\n",
    "    torch.cat(bg_axial).to(device),\n",
    "    torch.cat(bg_sagittal).to(device),\n",
    "    torch.cat(bg_coronal).to(device),\n",
    "    torch.cat(bg_meta).to(device),\n",
    "]\n",
    "\n",
    "test_input = [\n",
    "    torch.cat(test_axial).to(device),\n",
    "    torch.cat(test_sagittal).to(device),\n",
    "    torch.cat(test_coronal).to(device),\n",
    "    torch.cat(test_meta).to(device),\n",
    "]\n",
    "\n",
    "#explainer = shap.DeepExplainer(MultiModalWrapper(model), bg_input)\n",
    "#shap_values = explainer.shap_values(test_input, check_additivity=False)\n",
    "\n",
    "explainer = shap.GradientExplainer(MultiModalWrapper(model), bg_input)\n",
    "shap_values = explainer.shap_values(test_input)\n",
    "\n",
    "meta_shap = shap_values[3]               # SHAP values for metadata branch (shape: [n_samples, 2])\n",
    "meta_shap = np.squeeze(meta_shap)\n",
    "meta_input = test_input[3].cpu().numpy() # Original input values for metadata\n",
    "\n",
    "print(\"meta_shap shape:\", meta_shap.shape)       # should be (n_samples, 2)\n",
    "print(\"meta_input shape:\", meta_input.shape)\n",
    "\n",
    "shap.summary_plot(\n",
    "    meta_shap,\n",
    "    features=meta_input,\n",
    "    feature_names=[\"Age\", \"Gender\"]\n",
    ")\n",
    "\n",
    "shap_axial = shap_values[0][:, 0, :, :, 0]       # shape (24, 64, 64)\n",
    "image_axial = test_input[0][:, 0, :, :].cpu().numpy()  # shape (24, 64, 64)\n",
    "print(f\"shap_axial shape: {shap_axial.shape}, image_axial shape: {image_axial.shape}\")\n",
    "shap_coronal = shap_values[0][:, 1, :, :, 0]\n",
    "image_coronal = test_input[1][:, 0, :, :].cpu().numpy()\n",
    "print(f\"shap_coronal shape: {shap_coronal.shape}, image_coronal shape: {image_coronal.shape}\")\n",
    "shap_sagittal = shap_values[0][:, 2, :, :, 0]\n",
    "image_sagittal = test_input[2][:, 0, :, :].cpu().numpy()\n",
    "print(f\"shap_sagittal shape: {shap_sagittal.shape}, image_sagittal shape: {image_sagittal.shape}\")\n",
    "\n",
    "titles = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "for shap_img, input_img, title in zip(\n",
    "    [shap_axial, shap_coronal, shap_sagittal],\n",
    "    [image_axial, image_coronal, image_sagittal],\n",
    "    titles):\n",
    "    print(f\"Plotting SHAP for {title} view\")\n",
    "    shap.image_plot(shap_img, input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "# Load image data\n",
    "ct_img = nib.load(cropped_file_paths[\"CT\"])\n",
    "mask_img = nib.load(cropped_file_paths[\"Mask\"])\n",
    "lv_img = nib.load(cropped_file_paths[\"LV\"])\n",
    "rv_img = nib.load(cropped_file_paths[\"RV\"])\n",
    "la_img = nib.load(cropped_file_paths[\"LA\"])\n",
    "ra_img = nib.load(cropped_file_paths[\"RA\"])\n",
    "myo_img = nib.load(cropped_file_paths[\"MYO\"])\n",
    "ct_cropped = ct_img.get_fdata()\n",
    "mask_data = mask_img.get_fdata()\n",
    "lv_data = lv_img.get_fdata()\n",
    "rv_data = rv_img.get_fdata()\n",
    "la_data = la_img.get_fdata()\n",
    "ra_data = ra_img.get_fdata()\n",
    "myo_data = myo_img.get_fdata()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slices_from_png(png_slices_folder)\n",
    "crop_trim_resample_heart(input_folder, output_folder)\n",
    "plot_slices_masks(png_slices_folder, cropped_file_paths[\"CT\"], cropped_file_paths[\"Mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Shape: (512, 512, 311)\n",
      "original Orientation: ('L', 'A', 'S')\n",
      "Cropped Shape: (195, 149, 138)\n",
      "Cropped Orientation: ('R', 'A', 'S')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "og_lv =  nib.load(OG_file_paths[\"LV\"]).get_fdata()\n",
    "og_rv =  nib.load(OG_file_paths[\"RV\"]).get_fdata()\n",
    "og_la =  nib.load(OG_file_paths[\"LA\"]).get_fdata()\n",
    "og_ra =  nib.load(OG_file_paths[\"RA\"]).get_fdata()\n",
    "og_myo = nib.load(OG_file_paths[\"MYO\"]).get_fdata()\n",
    "og_ct =  nib.load(OG_file_paths[\"CT\"]).get_fdata()\n",
    "\n",
    "ct_cropped = nib.load(cropped_file_paths[\"CT\"]).get_fdata()\n",
    "lv_cropped = nib.load(cropped_file_paths[\"LV\"]).get_fdata()\n",
    "rv_cropped = nib.load(cropped_file_paths[\"RV\"]).get_fdata()\n",
    "la_cropped = nib.load(cropped_file_paths[\"LA\"]).get_fdata()\n",
    "ra_cropped = nib.load(cropped_file_paths[\"RA\"]).get_fdata()\n",
    "myo_cropped = nib.load(cropped_file_paths[\"MYO\"]).get_fdata()\n",
    "mask = nib.load(cropped_file_paths[\"Mask\"]).get_fdata()\n",
    "\n",
    "'''\n",
    "\n",
    "check_original_mask_alignment(ct_path=OG_file_paths[\"CT\"],mask_path=OG_file_paths[\"LV\"],world_mm=-125.8125,slice_axis='z',slice_index=170)\n",
    "\n",
    "ct_img = nib.load(OG_file_paths[\"CT\"])\n",
    "ct_data = ct_img.get_fdata()\n",
    "print(\"original Shape:\", ct_img.shape)\n",
    "print(\"original Orientation:\", aff2axcodes(ct_img.affine))  \n",
    "\n",
    "cropped_img = nib.load(cropped_file_paths[\"CT\"])\n",
    "cropped_data = cropped_img.get_fdata()\n",
    "print(\"Cropped Shape:\", cropped_img.shape)\n",
    "print(\"Cropped Orientation:\", aff2axcodes(cropped_img.affine))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19dbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 1048355585\n",
      "Modality: CT\n",
      "Series Description: Chest C+\n",
      "Slice Thickness: 1.25 mm\n",
      "Pixel Spacing: [0.615234, 0.615234] mm\n",
      "KVP (tube voltage): 120 kV\n",
      "Exposure Time: 600 ms\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import os\n",
    "\n",
    "tako='takotsubo_cases'\n",
    "case=tako\n",
    "patientID = \"XZC 32444390\"\n",
    "base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/{case}/{patientID}/DICOM/Chest C+\"  # {patient}/DICOM\n",
    "\n",
    "for filename in os.listdir(base_dicom_root):\n",
    "    if filename.endswith(\".dcm\"):\n",
    "        dcm = pydicom.dcmread(os.path.join(base_dicom_root, filename))\n",
    "        print(f\"Patient: {dcm.PatientName}\")\n",
    "        print(f\"Modality: {dcm.Modality}\")\n",
    "        print(f\"Series Description: {dcm.SeriesDescription}\")\n",
    "        print(f\"Slice Thickness: {dcm.SliceThickness} mm\")\n",
    "        print(f\"Pixel Spacing: {dcm.PixelSpacing} mm\")\n",
    "        print(f\"KVP (tube voltage): {dcm.get('KVP', 'N/A')} kV\")\n",
    "        print(f\"Exposure Time: {dcm.get('ExposureTime', 'N/A')} ms\")\n",
    "        break  # Only inspect one slice for now\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata extracted to dicom_metadata_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define base directory\n",
    "tako = 'takotsubo_cases'\n",
    "base_root = f\"../Takotsubo-Syndrome/data/Inputs/{tako}\"\n",
    "\n",
    "# Define output CSV\n",
    "output_csv = \"dicom_metadata_summary.csv\"\n",
    "fieldnames = [\n",
    "    \"PatientFolder\",\n",
    "    \"PatientName\",\n",
    "    \"Modality\",\n",
    "    \"SeriesDescription\",\n",
    "    \"SliceThickness_mm\",\n",
    "    \"PixelSpacing_mm\",\n",
    "    \"KVP_kV\",\n",
    "    \"ExposureTime_ms\"\n",
    "]\n",
    "\n",
    "# Collect metadata\n",
    "with open(output_csv, mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for patient_folder in os.listdir(base_root):\n",
    "        patient_path = os.path.join(base_root, patient_folder)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "\n",
    "        # Search for the first .dcm file recursively\n",
    "        dicom_file_found = False\n",
    "        for root, dirs, files in os.walk(patient_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(\".dcm\"):\n",
    "                    dicom_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        dcm = pydicom.dcmread(dicom_path, stop_before_pixels=True)\n",
    "                        writer.writerow({\n",
    "                            \"PatientFolder\": patient_folder,\n",
    "                            \"PatientName\": getattr(dcm, \"PatientName\", \"N/A\"),\n",
    "                            \"Modality\": getattr(dcm, \"Modality\", \"N/A\"),\n",
    "                            \"SeriesDescription\": getattr(dcm, \"SeriesDescription\", \"N/A\"),\n",
    "                            \"SliceThickness_mm\": getattr(dcm, \"SliceThickness\", \"N/A\"),\n",
    "                            \"PixelSpacing_mm\": getattr(dcm, \"PixelSpacing\", \"N/A\"),\n",
    "                            \"KVP_kV\": dcm.get(\"KVP\", \"N/A\"),\n",
    "                            \"ExposureTime_ms\": dcm.get(\"ExposureTime\", \"N/A\"),\n",
    "                        })\n",
    "                        dicom_file_found = True\n",
    "                        break  # Only inspect one DICOM file per patient\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to read {dicom_path}: {e}\")\n",
    "                        break\n",
    "            if dicom_file_found:\n",
    "                break\n",
    "        break \n",
    "\n",
    "print(f\"Metadata extracted to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
