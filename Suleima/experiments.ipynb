{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68df21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "from Suleima.core.preprocess import *\n",
    "from mydataloader import * \n",
    "from utils import *\n",
    "from SampleInfos import SampleInfo \n",
    "from Suleima.core.SamplePaths import SamplePath\n",
    "#import pyradiomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22d5b84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from totalsegmentator.python_api import totalsegmentator\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.orientations import aff2axcodes\n",
    "#from nibabel import Nifti1Image\n",
    "\n",
    "#import dicom2nifti\n",
    "#import dicom2nifti.convert_dicom\n",
    "\n",
    "import SimpleITK as sitk\n",
    "#import scipy.ndimage\n",
    "#from skimage import measure\n",
    "#import imageio\n",
    "\n",
    "\n",
    "#from monai.data.meta_tensor import MetaTensor\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import shap\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "from ipywidgets import interact\n",
    "\n",
    "\n",
    "import re\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260938af",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL='normal_cases'\n",
    "TAKO='takotsubo_cases'\n",
    "\n",
    "case_path=f\"{NORMAL}/LAAB 06958326_90M\"  #OG shape (512, 111, 512)\n",
    "case_path=f\"{NORMAL}/SS 10937555_61F\"   #OG shape (512, 86, 512)\n",
    "\n",
    "base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/{case_path}\" \n",
    "base_input_root = f\"data/Inputs/{case_path}\"\n",
    "base_output_root = f\"data/Outputs/{case_path}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49480a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for patientID in os.listdir(dicom_root):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a346932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_CT(volume_np, \n",
    "                spacing, \n",
    "                new_spacing=[1.0, 1.0, 1.0],\n",
    "                target_shape=(64, 64, 64), \n",
    "                original_affine=None):\n",
    "    \"\"\"\n",
    "    Resamples a CT volume using linear interpolation.\n",
    "    \"\"\"\n",
    "    sitk_img = sitk.GetImageFromArray(np.transpose(volume_np, (2, 1, 0)))\n",
    "    sitk_img.SetSpacing([float(s) for s in spacing[::-1]])\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkLinear)\n",
    "    \n",
    "    original_size = np.array(sitk_img.GetSize(), dtype=np.int32)\n",
    "    original_spacing = np.array(sitk_img.GetSpacing())\n",
    "    new_size = np.round(original_size * (original_spacing / new_spacing)).astype(int).tolist()\n",
    "    resampler.SetSize(new_size)\n",
    "    resampler.SetOutputSpacing(new_spacing)\n",
    "    resampler.SetOutputDirection(sitk_img.GetDirection())\n",
    "    resampler.SetOutputOrigin(sitk_img.GetOrigin())\n",
    "    resampled = resampler.Execute(sitk_img)\n",
    "\n",
    "    direction = np.array(resampled.GetDirection()).reshape(3, 3)\n",
    "    spacing_arr = np.array(resampled.GetSpacing())\n",
    "\n",
    "    origin = original_affine[:3, 3] if original_affine is not None else np.array(resampled.GetOrigin())\n",
    "    affine = np.eye(4)\n",
    "    affine[:3, :3] = direction * spacing_arr[:, None]\n",
    "    affine[:3, 3] = origin\n",
    "\n",
    "    resampled_np = np.transpose(sitk.GetArrayFromImage(resampled), (2, 1, 0))\n",
    "    zoom_factors = [t / s for t, s in zip(target_shape, resampled_np.shape)]\n",
    "    volume_final = scipy.ndimage.zoom(resampled_np, zoom=zoom_factors, order=1)\n",
    "\n",
    "    return volume_final, affine, resampled\n",
    "\n",
    "\n",
    "def resample_mask(volume_np, reference_image,\n",
    "                  target_shape=(64, 64, 64), original_affine=None):\n",
    "    \"\"\"\n",
    "    Resamples a binary or label mask using nearest-neighbour interpolation,\n",
    "    aligned to the given reference image (typically a CT volume).\n",
    "    \"\"\"\n",
    "    # Convert to SimpleITK image (z, y, x) format\n",
    "    sitk_img = sitk.GetImageFromArray(np.transpose(volume_np, (2, 1, 0)))\n",
    "\n",
    "    # Match mask to reference image geometry\n",
    "    sitk_img.SetSpacing(reference_image.GetSpacing())  # optional but safe\n",
    "\n",
    "    resampler = sitk.ResampleImageFilter()\n",
    "    resampler.SetInterpolator(sitk.sitkNearestNeighbor)\n",
    "    resampler.SetReferenceImage(reference_image)\n",
    "\n",
    "    resampled = resampler.Execute(sitk_img)\n",
    "\n",
    "    # Recover affine from reference image and spacing\n",
    "    direction = np.array(resampled.GetDirection()).reshape(3, 3)\n",
    "    spacing_arr = np.array(resampled.GetSpacing())\n",
    "    origin = original_affine[:3, 3] if original_affine is not None else np.array(resampled.GetOrigin())\n",
    "\n",
    "    affine = np.eye(4)\n",
    "    affine[:3, :3] = direction * spacing_arr[:, None]\n",
    "    affine[:3, 3] = origin\n",
    "\n",
    "    # Convert to NumPy in (x, y, z) order\n",
    "    resampled_np = np.transpose(sitk.GetArrayFromImage(resampled), (2, 1, 0))\n",
    "\n",
    "    # Resize to uniform shape\n",
    "    zoom_factors = [t / s for t, s in zip(target_shape, resampled_np.shape)]\n",
    "    volume_final = scipy.ndimage.zoom(resampled_np, zoom=zoom_factors, order=0)\n",
    "\n",
    "    return volume_final, affine, resampled\n",
    "\n",
    "\n",
    "def crop_trim_resample(case, Segment_root):\n",
    "    # === Step 3 - Crop, trim, and resample heart ===\n",
    "\n",
    "    OG_file = load_nifti(get_segments_paths(Segment_root))\n",
    "    lv = OG_file[\"LV\"][\"data\"]\n",
    "    rv = OG_file[\"RV\"][\"data\"]\n",
    "    la = OG_file[\"LA\"][\"data\"]\n",
    "    ra = OG_file[\"RA\"][\"data\"]\n",
    "    myo = OG_file[\"MYO\"][\"data\"]\n",
    "    og_ct_data = OG_file[\"CT\"][\"data\"]\n",
    "    og_ct_voxel = OG_file[\"CT\"][\"voxel\"]\n",
    "    og_affine=OG_file[\"CT\"][\"affine\"]\n",
    "    # Combine masks to find heart bounding box\n",
    "    binary_mask = ((lv + rv + la + ra + myo) > 0).astype(np.uint8)   # (sum of positive labels across all masks)  & turn the summed array into a binary mask\n",
    "    x_min, y_min, z_min = np.array(np.where(binary_mask)).min(axis=1)\n",
    "    x_max, y_max, z_max = np.array(np.where(binary_mask)).max(axis=1)\n",
    "    \n",
    "    # calculate crop boundaries (3D bounding box) \n",
    "    # identify min and max voxel coordinates where heart structures are present\n",
    "    x0, x1 = max(x_min, 0), min(x_max, og_ct_data.shape[0])\n",
    "    y0, y1 = max(y_min, 0), min(y_max, og_ct_data.shape[1])\n",
    "    z0, z1 = max(z_min, 0), min(z_max, og_ct_data.shape[2])\n",
    "    \n",
    "    # crop volumes with bounding box coordinates\n",
    "    ct_crop = og_ct_data[x0:x1, y0:y1, z0:z1]\n",
    "    lv_crop = lv[x0:x1, y0:y1, z0:z1]\n",
    "    rv_crop = rv[x0:x1, y0:y1, z0:z1]\n",
    "    la_crop = la[x0:x1, y0:y1, z0:z1]\n",
    "    ra_crop = ra[x0:x1, y0:y1, z0:z1]\n",
    "    myo_crop = myo[x0:x1, y0:y1, z0:z1]\n",
    "    \n",
    "    case.cropped_shape = ct_crop.shape\n",
    "    \n",
    "    # Further trim empty slices\n",
    "    # binary_mask = (sum of positive labels across all masks)  & turn the summed array back into a binary mask\n",
    "    binary_mask = ((lv_crop + rv_crop + la_crop + ra_crop + myo_crop) > 0).astype(np.uint8)\n",
    "    x_empty_indices = [i for i in range(binary_mask.shape[0]) if not np.any(binary_mask[i, :, :])]\n",
    "    y_empty_indices = [i for i in range(binary_mask.shape[1]) if not np.any(binary_mask[:, i, :])]\n",
    "    z_empty_indices = [i for i in range(binary_mask.shape[2]) if not np.any(binary_mask[:, :, i])]\n",
    "    \n",
    "    \n",
    "    #print(f\"cropped CT shape: {ct_crop.shape}, og_ct_voxel: {og_ct_voxel}\")\n",
    "    if x_empty_indices or y_empty_indices or z_empty_indices:\n",
    "        case.log_error(\n",
    "        f\"Empty slices â€” \"\n",
    "        f\"X: {x_empty_indices if x_empty_indices else 'None'}, \"\n",
    "        f\"Y: {y_empty_indices if y_empty_indices else 'None'}, \"\n",
    "        f\"Z: {z_empty_indices if z_empty_indices else 'None'} \"\n",
    "            )\n",
    "    \n",
    "    \n",
    "    ct_res, ct_affine, ct_resampled = resample_CT(ct_crop, \n",
    "                                             og_ct_voxel, \n",
    "                                             original_affine=og_affine)\n",
    "    lv_res, lv_affine, lv_resampled = resample_mask(lv_crop, ct_resampled, original_affine=og_affine)\n",
    "    \n",
    "    \n",
    "def crop(case):\n",
    "    # === Step 3 - Crop, trim, and resample heart ===\n",
    "    lv = case.lv\n",
    "    rv = case.rv\n",
    "    la = case.la\n",
    "    ra = case.ra\n",
    "    myo = case.myo\n",
    "    fullCT_data = case.ct_data\n",
    "    fullCT_voxel = case.ct_voxel\n",
    "    \n",
    "    binary_mask = ((lv + rv + la + ra + myo) > 0).astype(np.uint8)   # (sum of positive labels across all masks)  & turn the summed array into a binary mask\n",
    "    x_min, y_min, z_min = np.array(np.where(binary_mask)).min(axis=1)\n",
    "    x_max, y_max, z_max = np.array(np.where(binary_mask)).max(axis=1)\n",
    "    \n",
    "    # calculate crop boundaries (3D bounding box) \n",
    "    # identify min and max voxel coordinates where heart structures are present\n",
    "    x0, x1 = max(x_min, 0), min(x_max, og_ct_data.shape[0])\n",
    "    y0, y1 = max(y_min, 0), min(y_max, og_ct_data.shape[1])\n",
    "    z0, z1 = max(z_min, 0), min(z_max, og_ct_data.shape[2])\n",
    "    \n",
    "    case.log_error( f\"3D bounding box coordinates- \"\n",
    "                    f\"x: {x0}-{x1}, \"\n",
    "                    f\"y: {y0}-{y1}, \"\n",
    "                    f\"z: {z0}-{z1} \")\n",
    "    \n",
    "    # crop volumes with bounding box coordinates\n",
    "    ct_crop = og_ct_data[x0:x1, y0:y1, z0:z1]\n",
    "    lv_crop = lv[x0:x1, y0:y1, z0:z1]\n",
    "    rv_crop = rv[x0:x1, y0:y1, z0:z1]\n",
    "    la_crop = la[x0:x1, y0:y1, z0:z1]\n",
    "    ra_crop = ra[x0:x1, y0:y1, z0:z1]\n",
    "    myo_crop = myo[x0:x1, y0:y1, z0:z1]\n",
    "    \n",
    "    case.cropped_shape = ct_crop.shape\n",
    "    \n",
    "    # Further trim empty slices\n",
    "    # binary_mask = (sum of positive labels across all masks)  & turn the summed array back into a binary mask\n",
    "    binary_mask = ((lv_crop + rv_crop + la_crop + ra_crop + myo_crop) > 0).astype(np.uint8)\n",
    "    x_empty_indices = [i for i in range(binary_mask.shape[0]) if not np.any(binary_mask[i, :, :])]\n",
    "    y_empty_indices = [i for i in range(binary_mask.shape[1]) if not np.any(binary_mask[:, i, :])]\n",
    "    z_empty_indices = [i for i in range(binary_mask.shape[2]) if not np.any(binary_mask[:, :, i])]\n",
    "    \n",
    "    \n",
    "    #print(f\"cropped CT shape: {ct_crop.shape}, og_ct_voxel: {og_ct_voxel}\")\n",
    "    if x_empty_indices or y_empty_indices or z_empty_indices:\n",
    "        case.log_error(\n",
    "        f\"Empty slices â€” \"\n",
    "        f\"X: {x_empty_indices if x_empty_indices else 'None'}, \"\n",
    "        f\"Y: {y_empty_indices if y_empty_indices else 'None'}, \"\n",
    "        f\"Z: {z_empty_indices if z_empty_indices else 'None'} \"\n",
    "            )\n",
    "    \n",
    "\n",
    "def append_case_to_csv(case_obj, csv_path):\n",
    "    df = pd.DataFrame([case_obj.to_dict()])  \n",
    "    write_header = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', index=False, header=write_header)        \n",
    "\n",
    "CNTRL='CNTRL'\n",
    "TTS='TTS'\n",
    "        \n",
    "def process_case(group):\n",
    "    \n",
    "    if group == NORMAL:\n",
    "        CNTRL_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/normal_cases\" \n",
    "    elif group == TAKO:\n",
    "        base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/takotsubo_cases\"\n",
    "    base_root = f\"data/cases/\"\n",
    "    csv_path = f\"data/case_summary.csv\"\n",
    "    \n",
    "    # Step 1: Load already processed patient IDs from CSV\n",
    "    #if os.path.exists(csv_path):\n",
    "    #    existing_df = pd.read_csv(csv_path)\n",
    "    #    already_processed = set(existing_df[\"Case\"].astype(str))  # Assuming \"Case\" column stores patient_id\n",
    "    #else:\n",
    "    #    already_processed = set()\n",
    "\n",
    "    for patientID in os.listdir(base_dicom_root):\n",
    "        case_id=f\"{group}_{patientID}\"\n",
    "        case = SampleInfo(patient_id=case_id, \n",
    "                          path=SamplePath(\n",
    "              dicom_dir=os.path.join(base_dicom_root, patientID, \"DICOM\")\n",
    "            , patient_dir=os.path.join(base_root, case_id)\n",
    "            , segments_dir=os.path.join(base_root, case_id, \"Segments\")\n",
    "            , cropped_dir=os.path.join(base_root, case_id, \"Cropped\")\n",
    "            , resampled_dir=os.path.join(base_root, case_id, \"Resampled\")\n",
    "            , ctSlices_dir=os.path.join(base_root, case_id, \"CT_Slices\")\n",
    "            , segmentSlices_dir=os.path.join(base_root, case_id, \"Segment_Slices\")\n",
    "            , pngSlices_dir=os.path.join(base_root, case_id, \"PNG_Slices\"))) \n",
    "        \n",
    "        os.makedirs(case.path.patient_dir, exist_ok=True)\n",
    "        os.makedirs(case.path.segments_dir, exist_ok=True)\n",
    "        os.makedirs(case.path.cropped_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.resampled_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.ctSlices_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.segmentSlices_dir, exist_ok=True)\n",
    "        #os.makedirs(case.path.pngSlices_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "        \n",
    "        #if case_id in already_processed:\n",
    "        #    print(f\"Skipping already processed: {case_id}\")\n",
    "        #    continue\n",
    "        #print(f\"Patient ID: {patientID}\")\n",
    "   \n",
    "        \n",
    "        \n",
    "        # Load fullCT\n",
    "        if not os.path.exists(case.path.fullCT):\n",
    "            dicom2nifti.convert_dicom.dicom_series_to_nifti(case.path.dicom_dir, case.path.fullCT,)\n",
    "            case.fullCTnib = nib.load(case.path.fullCT)\n",
    "                \n",
    "            _ = totalsegmentator(\n",
    "                input_path=case.path.fullCT, \n",
    "                output_path=case.path.segments_dir,\n",
    "                license_number=\"aca_BWYHC6UQQFDU8A\",\n",
    "                task=\"heartchambers_highres\", \n",
    "                body_seg=True,\n",
    "                preview=True,\n",
    "                #ml=True,\n",
    "                radiomics=True\n",
    "            )\n",
    "        \n",
    "        \n",
    "        crop(case)\n",
    "        \n",
    "        # Check for resampled image\n",
    "        if not os.path.exists(case.path.croppedCT):\n",
    "            case.log_error(\"cropped_ct.nii.gz not found\")\n",
    "            missing = [key for key, path in case.path.segments.items() if not os.path.exists(path)]\n",
    "            case.missing_segments = missing\n",
    "            append_case_to_csv(case, csv_path)\n",
    "            continue\n",
    "\n",
    "        # Process resampled image\n",
    "        case.resampled = True\n",
    "        resampled_img = nib.load(resampled_path)\n",
    "        case.new_shape = resampled_img.shape\n",
    "        case.new_voxel = tuple(round(s, 3) for s in resampled_img.header.get_zooms())\n",
    "        case.new_orientation = aff2axcodes(resampled_img.affine)\n",
    "        \n",
    "        # Collect slice names\n",
    "        for slice in os.listdir(nii_slice_dir):\n",
    "            # if slice starts with ctX_ add file name to case.X_slices\n",
    "            if slice.startswith(\"ctX_\"):\n",
    "                case.X_slices.append(slice)\n",
    "            # if slice starts with ctY_ add file name to case.Y_slices\n",
    "            elif slice.startswith(\"ctY_\"):\n",
    "                case.Y_slices.append(slice)\n",
    "            # if slice starts with ctZ_ add file name to case.Z_slices\n",
    "            elif slice.startswith(\"ctZ_\"):\n",
    "                case.Z_slices.append(slice)\n",
    "            \n",
    "        crop(case, segment_path)\n",
    "        append_case_to_csv(case, csv_path)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ce5ce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient ID: AD 12191953\n",
      "Patient ID: AG 11370442\n",
      "Patient ID: AMH 36922300\n",
      "Patient ID: AMS 22722383\n",
      "Patient ID: APH 3516218\n",
      "Patient ID: BB 8903260\n",
      "Patient ID: BEH 4037842\n",
      "Patient ID: BFM 10624765\n",
      "Patient ID: BLT 11022191\n",
      "Patient ID: CAMcD 10747764\n",
      "Patient ID: CDA 38093134\n",
      "Patient ID: CLB 50002879\n",
      "Patient ID: CML 11113354\n",
      "Patient ID: CMS 4664231\n",
      "Patient ID: DCA 9939935\n",
      "Patient ID: DD 26362236\n",
      "Patient ID: DEM 9902248\n",
      "Patient ID: DIW 10053411\n",
      "Patient ID: DJD 6122410\n",
      "Patient ID: DJK 2493\n",
      "Patient ID: DJM 34687566\n",
      "Patient ID: ECW 33674557\n",
      "Patient ID: EIC 26844753\n",
      "Patient ID: ELD 30527501\n",
      "Patient ID: EMB 34404780\n",
      "Patient ID: FFJ 11086170\n",
      "Patient ID: GA 39800503\n",
      "Patient ID: GAB 25512591\n",
      "Patient ID: GB 10468072\n",
      "Patient ID: GHM 4514352\n",
      "Patient ID: GJB 30653190\n",
      "Patient ID: GJI 25633926\n",
      "Patient ID: HSM 3468857\n",
      "Patient ID: IK 6526404\n",
      "Patient ID: JAL 6996466\n",
      "Patient ID: JAQ 3124096\n",
      "Patient ID: JD 48020\n",
      "Patient ID: JDMB 13788\n",
      "Patient ID: JDMB 137882\n",
      "Patient ID: JEB 6123921\n",
      "Patient ID: JET 40340663\n",
      "Patient ID: JG 11495009\n",
      "Patient ID: JL 4008074\n",
      "Patient ID: JMB 38365177\n",
      "Patient ID: JMC 10182384\n",
      "Patient ID: JMCF 8687782\n",
      "Patient ID: JML 11878832\n",
      "Patient ID: JMMcC 4147591\n",
      "Patient ID: JNMP 2291631\n",
      "Patient ID: JNMP 22916312\n",
      "Patient ID: JOL 25671702\n",
      "Patient ID: JOS 38124012\n",
      "Patient ID: KA 28110559\n",
      "Patient ID: KAL 7224116\n",
      "Patient ID: KEK 5853320\n",
      "Patient ID: LAM 5515176\n",
      "Patient ID: LB 23518517\n",
      "Patient ID: LD 22194237\n",
      "Patient ID: LET 4456356\n",
      "Patient ID: LMA 3884426\n",
      "Patient ID: LMC 3629185\n",
      "Patient ID: LMD 22194237\n",
      "Patient ID: LW 12109724\n",
      "Patient ID: MA 6894703\n",
      "Patient ID: MB 12229480\n",
      "Patient ID: MC 3887643\n",
      "Patient ID: MDW 22867501\n",
      "Patient ID: MG 22519714\n",
      "Patient ID: MGR 2545663\n",
      "Patient ID: MK 25733700\n",
      "Patient ID: MMF 40610578\n",
      "Patient ID: MMStM 35433\n",
      "Patient ID: MVM 10108272\n",
      "Patient ID: NMC 90010075\n",
      "Patient ID: PAL 10614444\n",
      "Patient ID: PEB 5809140\n",
      "Patient ID: PEL 3437076\n",
      "Patient ID: PLM 36340719\n",
      "Patient ID: PMS 6674980\n",
      "Patient ID: RBB 5420187\n",
      "Patient ID: RMG 22721187\n",
      "Patient ID: SC 7249766\n",
      "Patient ID: SES 28300911\n",
      "Patient ID: SH 39969431\n",
      "Patient ID: SKLL 5171467\n",
      "Patient ID: SSA 35792472\n",
      "Patient ID: TS 2438216\n",
      "Patient ID: WF 10497121\n",
      "Patient ID: XZC 32444390\n",
      "Patient ID: YS 2685329\n",
      "Patient ID: ZCC 3076288\n"
     ]
    }
   ],
   "source": [
    "process_case(TAKO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93d65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_path=f\"{NORMAL}/SS 10937555_61F\"   #OG shape (512, 86, 512)\n",
    "\n",
    "Segment_root = f\"data/Inputs/{case_path}\"\n",
    "new_output_root = f\"data/New_Outputs/{case_path}\"\n",
    "os.makedirs(new_output_root, exist_ok=True)\n",
    "crop_trim_resample_heart(Segment_root, new_output_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "case=TAKO\n",
    "\n",
    "patientID = f\"{TAKO}/AG 11370442\"\n",
    "patientID = f\"{TAKO}/JMB 38365177\"\n",
    "patientID = f\"{TAKO}/JNMP 22916312\"\n",
    "patientID = f\"{TAKO}/HSM 3468857\"\n",
    "patientID = f\"{TAKO}/AMS 22722383\"\n",
    "patientID = f\"{TAKO}/BFM 10624765\"\n",
    "patientID = f\"{TAKO}/BLT 11022191\"\n",
    "patientID = f\"{TAKO}/EIC 26844753\"\n",
    "patientID = f\"{TAKO}/JDMB 137882\"\n",
    "\n",
    "OG_file_paths[\"LV\"]\n",
    "OG_file_paths[\"RV\"]\n",
    "OG_file_paths[\"LA\"]\n",
    "OG_file_paths[\"RA\"]\n",
    "OG_file_paths[\"MYO\"]\n",
    "OG_file_paths[\"CT\"]\n",
    "\n",
    "cropped_file_paths[\"Mask\"]\n",
    "cropped_file_paths[\"CT\"]\n",
    "cropped_file_paths[\"LV\"]\n",
    "cropped_file_paths[\"RV\"]\n",
    "cropped_file_paths[\"LA\"]\n",
    "cropped_file_paths[\"RA\"]\n",
    "cropped_file_paths[\"MYO\"]\n",
    "\n",
    "'''\n",
    "import os\n",
    "case=TAKO\n",
    "patientID = \"AG 11370442\"\n",
    "\n",
    "base_input_root = f\"data/Inputs/{case}\" #/{patient}\n",
    "base_output_root = f\"data/Outputs/{case}\" #/{patient}\n",
    "input_folder = os.path.join(base_input_root, patientID)\n",
    "output_folder = os.path.join(base_output_root, patientID)\n",
    "png_slices_folder=os.path.join(output_folder, \"png_slices\")\n",
    "\n",
    "cropped_file_paths = get_cropped_file_paths(output_folder)\n",
    "OG_file_paths = get_OG_file_paths(input_folder)\n",
    "\n",
    "#slice_CT(output_folder)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_trim_resample_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ad33ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "\n",
    "class SingleBranchCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(SingleBranchCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 16, kernel_size=3, padding=1)  # (B, 16, H, W)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.pool1 = nn.MaxPool2d(2)                                        # (B, 16, H/2, W/2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)            # (B, 32, H/2, W/2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.pool2 = nn.MaxPool2d(2)                                        # (B, 32, H/4, W/4)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(0.3)  # Dropout for feature maps\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.dropout(x)\n",
    "        return x  # Output shape: (B, 32, H/4, W/4)\n",
    "\n",
    "class MultiViewCNN(nn.Module):\n",
    "    def __init__(self, in_channels=3, input_size=(65, 65), use_metadata=False):\n",
    "        super(MultiViewCNN, self).__init__()\n",
    "\n",
    "        self.use_metadata = use_metadata\n",
    "        H, W = input_size\n",
    "\n",
    "        # Three branches\n",
    "        self.axial_branch = SingleBranchCNN(in_channels)\n",
    "        self.sagittal_branch = SingleBranchCNN(in_channels)\n",
    "        self.coronal_branch = SingleBranchCNN(in_channels)\n",
    "\n",
    "        # Output feature map size after 2x MaxPool2d(2)\n",
    "        flattened_size = 32 * (H // 4) * (W // 4)  # each branch output flattened\n",
    "\n",
    "        total_features = 3 * flattened_size       # all branches\n",
    "        if use_metadata:\n",
    "            total_features += 2  # e.g. age and gender\n",
    "\n",
    "        # Fully connected classifier\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(total_features, 128)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 1)  # Binary classification (output: logit)\n",
    "\n",
    "    def forward(self, axial, sagittal, coronal, meta=None):\n",
    "        a = self.axial_branch(axial)\n",
    "        s = self.sagittal_branch(sagittal)\n",
    "        c = self.coronal_branch(coronal)\n",
    "\n",
    "        a = a.view(a.size(0), -1)  # flatten\n",
    "        s = s.view(s.size(0), -1)\n",
    "        c = c.view(c.size(0), -1)\n",
    "\n",
    "        x = torch.cat([a, s, c], dim=1)\n",
    "\n",
    "        if self.use_metadata and meta is not None:\n",
    "            x = torch.cat([x, meta], dim=1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)  # no sigmoid here (use BCEWithLogitsLoss)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc624c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing normal_cases\n",
      "Processing takotsubo_cases\n",
      "Takotsubo: 81, Normal: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sulei\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50] | Train Loss: 0.9971 | Val Loss: 0.6446 | Train Acc: 52.29% | LR: 0.000100\n",
      "Epoch [2/50] | Train Loss: 0.6598 | Val Loss: 0.5989 | Train Acc: 65.14% | LR: 0.000100\n",
      "Epoch [3/50] | Train Loss: 0.5735 | Val Loss: 0.5771 | Train Acc: 67.89% | LR: 0.000100\n",
      "Epoch [4/50] | Train Loss: 0.5403 | Val Loss: 0.5984 | Train Acc: 72.48% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [5/50] | Train Loss: 0.4076 | Val Loss: 0.5515 | Train Acc: 82.57% | LR: 0.000100\n",
      "Epoch [6/50] | Train Loss: 0.4270 | Val Loss: 0.5997 | Train Acc: 82.57% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [7/50] | Train Loss: 0.3281 | Val Loss: 0.4957 | Train Acc: 87.16% | LR: 0.000100\n",
      "Epoch [8/50] | Train Loss: 0.3458 | Val Loss: 0.5179 | Train Acc: 88.07% | LR: 0.000100\n",
      "No improvement in val loss (1/3)\n",
      "Epoch [9/50] | Train Loss: 0.2221 | Val Loss: 0.6800 | Train Acc: 89.91% | LR: 0.000100\n",
      "No improvement in val loss (2/3)\n",
      "Epoch [10/50] | Train Loss: 0.1738 | Val Loss: 0.5386 | Train Acc: 95.41% | LR: 0.000100\n",
      "No improvement in val loss (3/3)\n",
      "Early stopping triggered.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "metadata, labels, slices = load_dataset()\n",
    "dataset = SliceDataset(\n",
    "    slices_dict=slices,          \n",
    "    metadata_dict=metadata,      \n",
    "    labels_dict=labels           \n",
    ")\n",
    "\n",
    "takotsubo_count = sum(1 for sample in dataset if sample[\"label\"].item() == 1)\n",
    "normal_count = sum(1 for sample in dataset if sample[\"label\"].item() == 0)\n",
    "\n",
    "print(f\"Takotsubo: {takotsubo_count}, Normal: {normal_count}\")\n",
    "\n",
    "dataset_loader = DataLoaderModule(dataset, batch_size=1)\n",
    "\n",
    "# Model setup\n",
    "model = MultiViewCNN(in_channels=3, input_size=(65, 65), use_metadata=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "#class_weight = takotsubo_count / normal_count if normal_count > 0 else 1.0\n",
    "pos_weight = torch.tensor([takotsubo_count / normal_count])  \n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device))\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
    "train_loader = dataset_loader.get_train_loader()\n",
    "val_loader = dataset_loader.get_val_loader()\n",
    "test_loader = dataset_loader.get_test_loader()\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "threshold_cutoff = 0.5  # threshold for binary classification\n",
    "patience = 3\n",
    "patience_counter = 0\n",
    "num_epochs = 50  # longer max epochs now\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        x_axial = batch[\"axial\"].to(device)\n",
    "        x_sagittal = batch[\"sagittal\"].to(device)\n",
    "        x_coronal = batch[\"coronal\"].to(device)\n",
    "        x_meta = batch[\"meta\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "        loss = criterion(outputs, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        predicted = (torch.sigmoid(outputs) > threshold_cutoff).float()\n",
    "        total += y.size(0)\n",
    "        correct += (predicted == y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    # ====== Validation ======\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_axial = batch[\"axial\"].to(device)\n",
    "            x_sagittal = batch[\"sagittal\"].to(device)\n",
    "            x_coronal = batch[\"coronal\"].to(device)\n",
    "            x_meta = batch[\"meta\"].to(device)\n",
    "            y = batch[\"label\"].to(device)\n",
    "\n",
    "            outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "            loss = criterion(outputs, y)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Train Acc: {train_acc:.2f}% | LR: {current_lr:.6f}\")\n",
    "    scheduler.step(avg_val_loss)\n",
    "    # ====== Early stopping check ======\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pt\")  # save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement in val loss ({patience_counter}/{patience})\")\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# ========== TEST EVALUATION WITH ROC AUC ========== #\n",
    "\n",
    "\n",
    "# Load best model\n",
    "torch.save(model.state_dict(), \"best_model.pt\")\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_prob = []\n",
    "threshold_cutoff = 0.5  # threshold for binary classification\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        x_axial = batch[\"axial\"].to(device)\n",
    "        x_sagittal = batch[\"sagittal\"].to(device)\n",
    "        x_coronal = batch[\"coronal\"].to(device)\n",
    "        x_meta = batch[\"meta\"].to(device)\n",
    "        y = batch[\"label\"].to(device)\n",
    "\n",
    "        outputs = model(x_axial, x_sagittal, x_coronal, x_meta)\n",
    "        probs = torch.sigmoid(outputs).cpu().numpy()  # shape (B, 1)\n",
    "\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_prob.extend(probs)\n",
    "\n",
    "# Flatten\n",
    "y_true = [int(x) for x in y_true]\n",
    "y_prob = [float(p) for p in y_prob]\n",
    "y_pred = [int(p > threshold_cutoff) for p in y_prob]\n",
    "\n",
    "# Report\n",
    "print(\"\\nðŸ“Š Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Normal\", \"Takotsubo\"]))\n",
    "\n",
    "# ROC AUC\n",
    "auc_score = roc_auc_score(y_true, y_prob)\n",
    "print(f\"ðŸŽ¯ ROC AUC Score: {auc_score:.4f}\")\n",
    "\n",
    "# ROC Curve plot (optional)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {auc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Normal\", \"Takotsubo\"])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataModelWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, meta):\n",
    "        # Create dummy tensors for image branches\n",
    "        batch_size = meta.size(0)\n",
    "        dummy = torch.zeros((batch_size, 3, 65, 65)).to(meta.device)\n",
    "        return self.model(dummy, dummy, dummy, meta)\n",
    "    \n",
    "class MultiModalWrapper(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, axial, sagittal, coronal, meta):\n",
    "        return self.model(axial, sagittal, coronal, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f24da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect background (for DeepExplainer) and test examples\n",
    "bg_axial, bg_sagittal, bg_coronal, bg_meta = [], [], [], []\n",
    "test_axial, test_sagittal, test_coronal, test_meta = [], [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, batch in enumerate(dataset_loader.get_val_loader()):\n",
    "        if i >= 10: break  # Limit background\n",
    "        bg_axial.append(batch[\"axial\"])\n",
    "        bg_sagittal.append(batch[\"sagittal\"])\n",
    "        bg_coronal.append(batch[\"coronal\"])\n",
    "        bg_meta.append(batch[\"meta\"])\n",
    "\n",
    "    for batch in dataset_loader.get_test_loader():\n",
    "        test_axial.append(batch[\"axial\"])\n",
    "        test_sagittal.append(batch[\"sagittal\"])\n",
    "        test_coronal.append(batch[\"coronal\"])\n",
    "        test_meta.append(batch[\"meta\"])\n",
    "\n",
    "# Stack all background and test tensors\n",
    "bg_input = [\n",
    "    torch.cat(bg_axial).to(device),\n",
    "    torch.cat(bg_sagittal).to(device),\n",
    "    torch.cat(bg_coronal).to(device),\n",
    "    torch.cat(bg_meta).to(device),\n",
    "]\n",
    "\n",
    "test_input = [\n",
    "    torch.cat(test_axial).to(device),\n",
    "    torch.cat(test_sagittal).to(device),\n",
    "    torch.cat(test_coronal).to(device),\n",
    "    torch.cat(test_meta).to(device),\n",
    "]\n",
    "\n",
    "#explainer = shap.DeepExplainer(MultiModalWrapper(model), bg_input)\n",
    "#shap_values = explainer.shap_values(test_input, check_additivity=False)\n",
    "\n",
    "explainer = shap.GradientExplainer(MultiModalWrapper(model), bg_input)\n",
    "shap_values = explainer.shap_values(test_input)\n",
    "\n",
    "meta_shap = shap_values[3]               # SHAP values for metadata branch (shape: [n_samples, 2])\n",
    "meta_shap = np.squeeze(meta_shap)\n",
    "meta_input = test_input[3].cpu().numpy() # Original input values for metadata\n",
    "\n",
    "print(\"meta_shap shape:\", meta_shap.shape)       # should be (n_samples, 2)\n",
    "print(\"meta_input shape:\", meta_input.shape)\n",
    "\n",
    "shap.summary_plot(\n",
    "    meta_shap,\n",
    "    features=meta_input,\n",
    "    feature_names=[\"Age\", \"Gender\"]\n",
    ")\n",
    "\n",
    "shap_axial = shap_values[0][:, 0, :, :, 0]       # shape (24, 64, 64)\n",
    "image_axial = test_input[0][:, 0, :, :].cpu().numpy()  # shape (24, 64, 64)\n",
    "print(f\"shap_axial shape: {shap_axial.shape}, image_axial shape: {image_axial.shape}\")\n",
    "shap_coronal = shap_values[0][:, 1, :, :, 0]\n",
    "image_coronal = test_input[1][:, 0, :, :].cpu().numpy()\n",
    "print(f\"shap_coronal shape: {shap_coronal.shape}, image_coronal shape: {image_coronal.shape}\")\n",
    "shap_sagittal = shap_values[0][:, 2, :, :, 0]\n",
    "image_sagittal = test_input[2][:, 0, :, :].cpu().numpy()\n",
    "print(f\"shap_sagittal shape: {shap_sagittal.shape}, image_sagittal shape: {image_sagittal.shape}\")\n",
    "\n",
    "titles = [\"Axial\", \"Coronal\", \"Sagittal\"]\n",
    "for shap_img, input_img, title in zip(\n",
    "    [shap_axial, shap_coronal, shap_sagittal],\n",
    "    [image_axial, image_coronal, image_sagittal],\n",
    "    titles):\n",
    "    print(f\"Plotting SHAP for {title} view\")\n",
    "    shap.image_plot(shap_img, input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e281c544",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "\n",
    "# Load image data\n",
    "ct_img = nib.load(cropped_file_paths[\"CT\"])\n",
    "mask_img = nib.load(cropped_file_paths[\"Mask\"])\n",
    "lv_img = nib.load(cropped_file_paths[\"LV\"])\n",
    "rv_img = nib.load(cropped_file_paths[\"RV\"])\n",
    "la_img = nib.load(cropped_file_paths[\"LA\"])\n",
    "ra_img = nib.load(cropped_file_paths[\"RA\"])\n",
    "myo_img = nib.load(cropped_file_paths[\"MYO\"])\n",
    "ct_cropped = ct_img.get_fdata()\n",
    "mask_data = mask_img.get_fdata()\n",
    "lv_data = lv_img.get_fdata()\n",
    "rv_data = rv_img.get_fdata()\n",
    "la_data = la_img.get_fdata()\n",
    "ra_data = ra_img.get_fdata()\n",
    "myo_data = myo_img.get_fdata()\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb4ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_slices_from_png(png_slices_folder)\n",
    "crop_trim_resample_heart(input_folder, output_folder)\n",
    "plot_slices_masks(png_slices_folder, cropped_file_paths[\"CT\"], cropped_file_paths[\"Mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0d0b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original Shape: (512, 512, 311)\n",
      "original Orientation: ('L', 'A', 'S')\n",
      "Cropped Shape: (195, 149, 138)\n",
      "Cropped Orientation: ('R', 'A', 'S')\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "og_lv =  nib.load(OG_file_paths[\"LV\"]).get_fdata()\n",
    "og_rv =  nib.load(OG_file_paths[\"RV\"]).get_fdata()\n",
    "og_la =  nib.load(OG_file_paths[\"LA\"]).get_fdata()\n",
    "og_ra =  nib.load(OG_file_paths[\"RA\"]).get_fdata()\n",
    "og_myo = nib.load(OG_file_paths[\"MYO\"]).get_fdata()\n",
    "og_ct =  nib.load(OG_file_paths[\"CT\"]).get_fdata()\n",
    "\n",
    "ct_cropped = nib.load(cropped_file_paths[\"CT\"]).get_fdata()\n",
    "lv_cropped = nib.load(cropped_file_paths[\"LV\"]).get_fdata()\n",
    "rv_cropped = nib.load(cropped_file_paths[\"RV\"]).get_fdata()\n",
    "la_cropped = nib.load(cropped_file_paths[\"LA\"]).get_fdata()\n",
    "ra_cropped = nib.load(cropped_file_paths[\"RA\"]).get_fdata()\n",
    "myo_cropped = nib.load(cropped_file_paths[\"MYO\"]).get_fdata()\n",
    "mask = nib.load(cropped_file_paths[\"Mask\"]).get_fdata()\n",
    "\n",
    "'''\n",
    "\n",
    "check_original_mask_alignment(ct_path=OG_file_paths[\"CT\"],mask_path=OG_file_paths[\"LV\"],world_mm=-125.8125,slice_axis='z',slice_index=170)\n",
    "\n",
    "ct_img = nib.load(OG_file_paths[\"CT\"])\n",
    "ct_data = ct_img.get_fdata()\n",
    "print(\"original Shape:\", ct_img.shape)\n",
    "print(\"original Orientation:\", aff2axcodes(ct_img.affine))  \n",
    "\n",
    "cropped_img = nib.load(cropped_file_paths[\"CT\"])\n",
    "cropped_data = cropped_img.get_fdata()\n",
    "print(\"Cropped Shape:\", cropped_img.shape)\n",
    "print(\"Cropped Orientation:\", aff2axcodes(cropped_img.affine))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e19dbf4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: 1048355585\n",
      "Modality: CT\n",
      "Series Description: Chest C+\n",
      "Slice Thickness: 1.25 mm\n",
      "Pixel Spacing: [0.615234, 0.615234] mm\n",
      "KVP (tube voltage): 120 kV\n",
      "Exposure Time: 600 ms\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import os\n",
    "\n",
    "tako='takotsubo_cases'\n",
    "case=tako\n",
    "patientID = \"XZC 32444390\"\n",
    "base_dicom_root = f\"../Takotsubo-Syndrome/data/Inputs/{case}/{patientID}/DICOM/Chest C+\"  # {patient}/DICOM\n",
    "\n",
    "for filename in os.listdir(base_dicom_root):\n",
    "    if filename.endswith(\".dcm\"):\n",
    "        dcm = pydicom.dcmread(os.path.join(base_dicom_root, filename))\n",
    "        print(f\"Patient: {dcm.PatientName}\")\n",
    "        print(f\"Modality: {dcm.Modality}\")\n",
    "        print(f\"Series Description: {dcm.SeriesDescription}\")\n",
    "        print(f\"Slice Thickness: {dcm.SliceThickness} mm\")\n",
    "        print(f\"Pixel Spacing: {dcm.PixelSpacing} mm\")\n",
    "        print(f\"KVP (tube voltage): {dcm.get('KVP', 'N/A')} kV\")\n",
    "        print(f\"Exposure Time: {dcm.get('ExposureTime', 'N/A')} ms\")\n",
    "        break  # Only inspect one slice for now\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f3056a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata extracted to dicom_metadata_summary.csv\n"
     ]
    }
   ],
   "source": [
    "import pydicom\n",
    "import os\n",
    "import csv\n",
    "\n",
    "# Define base directory\n",
    "tako = 'takotsubo_cases'\n",
    "base_root = f\"../Takotsubo-Syndrome/data/Inputs/{tako}\"\n",
    "\n",
    "# Define output CSV\n",
    "output_csv = \"dicom_metadata_summary.csv\"\n",
    "fieldnames = [\n",
    "    \"PatientFolder\",\n",
    "    \"PatientName\",\n",
    "    \"Modality\",\n",
    "    \"SeriesDescription\",\n",
    "    \"SliceThickness_mm\",\n",
    "    \"PixelSpacing_mm\",\n",
    "    \"KVP_kV\",\n",
    "    \"ExposureTime_ms\"\n",
    "]\n",
    "\n",
    "# Collect metadata\n",
    "with open(output_csv, mode='w', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "\n",
    "    for patient_folder in os.listdir(base_root):\n",
    "        patient_path = os.path.join(base_root, patient_folder)\n",
    "        if not os.path.isdir(patient_path):\n",
    "            continue\n",
    "\n",
    "        # Search for the first .dcm file recursively\n",
    "        dicom_file_found = False\n",
    "        for root, dirs, files in os.walk(patient_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(\".dcm\"):\n",
    "                    dicom_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        dcm = pydicom.dcmread(dicom_path, stop_before_pixels=True)\n",
    "                        writer.writerow({\n",
    "                            \"PatientFolder\": patient_folder,\n",
    "                            \"PatientName\": getattr(dcm, \"PatientName\", \"N/A\"),\n",
    "                            \"Modality\": getattr(dcm, \"Modality\", \"N/A\"),\n",
    "                            \"SeriesDescription\": getattr(dcm, \"SeriesDescription\", \"N/A\"),\n",
    "                            \"SliceThickness_mm\": getattr(dcm, \"SliceThickness\", \"N/A\"),\n",
    "                            \"PixelSpacing_mm\": getattr(dcm, \"PixelSpacing\", \"N/A\"),\n",
    "                            \"KVP_kV\": dcm.get(\"KVP\", \"N/A\"),\n",
    "                            \"ExposureTime_ms\": dcm.get(\"ExposureTime\", \"N/A\"),\n",
    "                        })\n",
    "                        dicom_file_found = True\n",
    "                        break  # Only inspect one DICOM file per patient\n",
    "                    except Exception as e:\n",
    "                        print(f\"Failed to read {dicom_path}: {e}\")\n",
    "                        break\n",
    "            if dicom_file_found:\n",
    "                break\n",
    "        break \n",
    "\n",
    "print(f\"Metadata extracted to {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
