timestamp,optimizer,Patience,weight_decay,threshold_cutoff,dropout_rate,padd_size,ker_size,Epoch,Train Loss,Val Loss,Train Acc,Val Acc,Learning Rate,Best Val Loss
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,1,7.8183,1.3116,54.13,65.22,0.001,1.3116
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,2,3.2779,1.1702,44.04,52.17,0.001,1.1702
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,3,1.0288,0.6776,60.55,60.87,0.001,0.6776
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,4,0.5744,0.6080,69.72,73.91,0.001,0.6080
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,5,0.5706,0.6591,67.89,60.87,0.001,0.6080
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,6,0.5749,0.6063,72.48,78.26,0.001,0.6063
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,7,0.6296,0.6038,67.89,60.87,0.001,0.6038
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,8,0.5417,0.5542,76.15,78.26,0.001,0.5542
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,9,0.5113,0.5662,76.15,78.26,0.001,0.5542
2025-06-30 21:22,Adam,3,0.0001,0.5,0.4,1,2,10,0.7092,0.6631,67.89,60.87,0.001,0.5542
